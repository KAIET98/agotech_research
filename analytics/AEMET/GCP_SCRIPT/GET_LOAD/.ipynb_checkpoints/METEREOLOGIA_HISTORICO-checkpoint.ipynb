{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/KAIET98/TFM_AGROTECH/blob/develop/analytics/AEMET/GCP_SCRIPT/METEREOLOGIA_HISTORICO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "e-1w3jnysBJv"
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Importamos este paquete para eliminar los warnings que nos pueda llegar a generar l afuncioón\n",
    "\n",
    "'''\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "\n",
    "'''\n",
    "Este script tiene como objetvio automatizar la captación de todos los datos metereologicos\n",
    "de una estación cualquiera de españa que se le proporcione\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "from pickle import NONE\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from geopy.distance import geodesic\n",
    "from folium import FeatureGroup \n",
    "import folium\n",
    "import googlemaps\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from funciones_auxiliares.lat_lon import latitud_decimal, longitud_decimal\n",
    "\n",
    "from funciones_auxiliares.province_search import *\n",
    "\n",
    "from funciones_auxiliares.province_extraction import search_province\n",
    "\n",
    "class mi_metereologia: \n",
    "\n",
    "    def __init__(self, informacion_adress  = None, google_maps_key = None, coodenadas = None, api_aemet = None, fecha_ini = None, fecha_fin = None):\n",
    "\n",
    "        self.adress =  informacion_adress\n",
    "\n",
    "        self.google_maps = google_maps_key\n",
    "\n",
    "        self.aemet = api_aemet\n",
    "\n",
    "        self.coordenadas = coodenadas\n",
    "\n",
    "        self.fecha_ini = fecha_ini\n",
    "\n",
    "        self.fecha_fin = fecha_fin\n",
    "\n",
    "        if self.coordenadas != None:\n",
    "\n",
    "            print('Busqueda por coordenadas')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    Obtenemos la provincia donde vive el usuario\n",
    "    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    def address(self):\n",
    "\n",
    "        \n",
    "        if self.coordenadas != None:\n",
    "\n",
    "            gmaps = googlemaps.Client(key=self.google_maps)\n",
    "\n",
    "            coordenadas = self.coordenadas\n",
    "\n",
    "            reverse_geocode_result = gmaps.reverse_geocode(coordenadas)\n",
    "\n",
    "            for element in reverse_geocode_result[0]:\n",
    "\n",
    "                print(element, end = \"\\n\")\n",
    "\n",
    "                if isinstance(element[0], dict):\n",
    "\n",
    "                    for elekey in element[0].keys():\n",
    "\n",
    "                        print(element, '  ', element[0][elekey], \"\\n\") \n",
    "                else: \n",
    "\n",
    "                    print('{} es una lista'.format(element))\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "            if 'long_name' in reverse_geocode_result[0]['address_components'][3]: \n",
    "\n",
    "                print('la provincia es: ', reverse_geocode_result[0]['address_components'][3]['long_name'])\n",
    "\n",
    "\n",
    "                self.resultado  = reverse_geocode_result[0]['address_components'][3]['long_name']\n",
    "\n",
    "\n",
    "                if 'geometry' in reverse_geocode_result[0].keys(): \n",
    "\n",
    "                    if 'location' in reverse_geocode_result[0]['geometry']:\n",
    "\n",
    "\n",
    "                        self.latitude = reverse_geocode_result[0]['geometry']['location']['lat']\n",
    "\n",
    "                        self.longitude = reverse_geocode_result[0]['geometry']['location']['lng']\n",
    "\n",
    "\n",
    "\n",
    "                        print('Tenemos info geolocalizada :)', '\\n', self.latitude , \", \", self.longitude)\n",
    "                    \n",
    "                    try: \n",
    "\n",
    "                        self.provincia = search_province(reverse_geocode_result[0]).upper()\n",
    "\n",
    "                        #self.provincia = reverse_geocode_result[0]['address_components'][3]['long_name'].upper()\n",
    "\n",
    "                        print('Provincia optenida :)', '\\n', self.provincia )\n",
    "\n",
    "\n",
    "                    #Ejecutamos la función de visualización del mapa\n",
    "\n",
    "                    # mapa = ver_mapa(provincia)\n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    except: \n",
    "\n",
    "\n",
    "                        print('No se puede sacar la provincia')\n",
    "\n",
    "        \n",
    "        else:\n",
    "\n",
    "\n",
    "            gmaps = googlemaps.Client(key=self.google_maps)\n",
    "            \n",
    "            geocode_result = gmaps.geocode(str(self.adress))\n",
    "\n",
    "            if 'geometry' in geocode_result[0].keys(): \n",
    "\n",
    "                if 'location' in geocode_result[0]['geometry']:\n",
    "\n",
    "\n",
    "                    latitude = geocode_result[0]['geometry']['location']['lat']\n",
    "\n",
    "                    longitude = geocode_result[0]['geometry']['location']['lng']\n",
    "\n",
    "\n",
    "\n",
    "                    print('Tenemos info geolocalizada :)', '\\n')\n",
    "\n",
    "                try: \n",
    "\n",
    "                    self.provincia = geocode_result[0]['address_components'][3]['long_name'].upper()\n",
    "\n",
    "                    print('Provincia optenida :)', '\\n', self.provincia )\n",
    "\n",
    "\n",
    "                #Ejecutamos la función de visualización del mapa\n",
    "\n",
    "                # mapa = ver_mapa(provincia)\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "                except: \n",
    "\n",
    "\n",
    "                    print('No se puede sacar la provincia')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        #return mapa\n",
    "\n",
    "        return self.provincia\n",
    "\n",
    "\n",
    "\n",
    "    def estaciones(self): \n",
    "\n",
    "        #1. Primero sacamos cuale son las estaciones de españa\n",
    "\n",
    "\n",
    "        url = \"https://opendata.aemet.es/opendata/api/valores/climatologicos/inventarioestaciones/todasestaciones/\"\n",
    "\n",
    "        #api_key = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJraWdsZXNpYXNiYXJhaWJhckBzdHVkZW50LmVhZS5lcyIsImp0aSI6ImY4YWQ5OGRmLTkzMjQtNDEzMi05NjY3LTdjY2E2Nzc3Mzc0NiIsImlzcyI6IkFFTUVUIiwiaWF0IjoxNjQyOTYzODc0LCJ1c2VySWQiOiJmOGFkOThkZi05MzI0LTQxMzItOTY2Ny03Y2NhNjc3NzM3NDYiLCJyb2xlIjoiIn0.en7xw4HHYaZ4oW8qooX6wGG3yn1Tv3OzFfnhrZac6vo'\n",
    "        querystring = {\"api_key\":self.aemet}\n",
    "\n",
    "        headers = {\n",
    "            'cache-control': \"no-cache\"\n",
    "            }\n",
    "\n",
    "        response = json.loads(requests.request(\"GET\", url, headers=headers, params=querystring).text)\n",
    "\n",
    "        if response['estado'] == requests.codes.OK:\n",
    "\n",
    "            #nos hacemos con el enlace\n",
    "            enlace  = json.loads(requests.request(\"GET\", url, headers=headers, params=querystring).text)['datos']\n",
    "\n",
    "            estaciones = pd.DataFrame(requests.get(enlace, params=querystring, verify=False).json())\n",
    "\n",
    "        \n",
    "        if self.provincia == 'VALENCIAN COMMUNITY':\n",
    "          \n",
    "          self.provincia = 'VALENCIA'\n",
    "\n",
    "        if self.provincia == 'CASTILE-LA MANCHA':\n",
    "          \n",
    "          self.provincia = 'CASTILLA-LA MANCHA'\n",
    "\n",
    "        print(estaciones['provincia'].unique())\n",
    "        \n",
    "\n",
    "        estaciones_provincia = estaciones[estaciones['provincia'] == self.provincia][['indicativo', 'latitud', 'nombre', 'longitud']]\n",
    "\n",
    "\n",
    "\n",
    "        #2. Filtramos las estaciones por la provincia que me corresponde como usuario\n",
    "\n",
    "\n",
    "        #modiifico laas columnas de latitud y longitud\n",
    "\n",
    "\n",
    "        estaciones_provincia['latitud_num_or']= estaciones_provincia.latitud.str.extract('(\\d+)')\n",
    "        estaciones_provincia['longitud_num_or']= estaciones_provincia.longitud.str.extract('(\\d+)')\n",
    "\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia[[\"indicativo\", \"nombre\", \"latitud_num_or\",  \"longitud_num_or\"]]\n",
    "\n",
    "\n",
    "        # cambiamos los nombres de las columnas\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia.rename(columns={'nombre': 'Estacion', 'latitud_num_or': 'Latitud', 'longitud_num_or': 'Longitud'})[['Estacion', \t'Latitud', \t'Longitud', 'indicativo']].reset_index().drop('index', axis = 1)\n",
    "\n",
    "        #definimos la lista donde guardaremos los resultados\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        Importamos las funciones de modificacion de datos de longitud latitud\n",
    "        \n",
    "        \n",
    "\n",
    "        def latitud_decimal(latitud_ini, lista):\n",
    "            \n",
    "            grados_lat = latitud_ini[:2]\n",
    "            min_lat = int(latitud_ini[2:4])/60\n",
    "            seg_lat = int(latitud_ini[4:6])/3600\n",
    "            latitud_decim = int(grados_lat)+min_lat+seg_lat\n",
    "            \n",
    "            #guardamos el resultado en una lista\n",
    "\n",
    "            lista.append(latitud_decim)\n",
    "\n",
    "\n",
    "\n",
    "        def longitud_decimal(longitud_ini, lista_lon):\n",
    "\n",
    "            grados_lon = longitud_ini[:2]\n",
    "            min_lon = int(longitud_ini[2:4])/60\n",
    "            seg_lon = int(longitud_ini[4:6])/3600\n",
    "            longitud_decim = -1*(int(grados_lon)+min_lon+seg_lon)\n",
    "\n",
    "            lista_lon.append(longitud_decim)\n",
    "\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "        #0. Definimos las listas donde gaurdaremos los resultados de las localizacion\n",
    "        #es de las estaciones\n",
    "        latitudes = []\n",
    "        lista_longitudes = []\n",
    "\n",
    "        #print('El tamaño de esatciones_provincia es: ', len(estaciones_provincia))\n",
    "\n",
    "        #print(estaciones_provincia)\n",
    "\n",
    "        #Transformaeremos cada laittud y longitud qu eencontremos en el dataset \n",
    "        for linea in range(len(estaciones_provincia)):\n",
    "\n",
    "        #1. Luego definimos las funcioens para obtener los resutlados\n",
    "\n",
    "            latitud_decimal(estaciones_provincia.iloc[linea,1], latitudes)\n",
    "            longitud_decimal(estaciones_provincia.iloc[linea,2], lista_longitudes)\n",
    "\n",
    "\n",
    "        estaciones_provincia['latitud_of'] = latitudes\n",
    "\n",
    "        estaciones_provincia['longitud_of'] = lista_longitudes\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia[['Estacion', 'latitud_of', 'longitud_of', 'indicativo']]\n",
    "\n",
    "        self.estaciones_provincia = estaciones_provincia.rename(columns = {'latitud': 'latitud_of', 'longitud':'longitud_of'})\n",
    "\n",
    "        return self.estaciones_provincia\n",
    "        \n",
    "\n",
    "\n",
    "    #vemos cuales son mis estaciones mas cercanas\n",
    "\n",
    "\n",
    "    def mi_latlon(self):\n",
    "\n",
    "        self.addressgmaps = googlemaps.Client(key=self.google_maps)\n",
    "\n",
    "\n",
    "        if self.coordenadas != None:\n",
    "\n",
    "            \n",
    "\n",
    "            coordenadas = self.coordenadas\n",
    "            \n",
    "            reverse_geocode_result = self.addressgmaps.reverse_geocode(coordenadas)\n",
    "             \n",
    "\n",
    "           # print(reverse_geocode_result[0].keys())\n",
    "\n",
    "\n",
    "            if 'geometry' in reverse_geocode_result[0].keys(): \n",
    "\n",
    "                #print(reverse_geocode_result[0]['geometry'])\n",
    "\n",
    "                    if 'location' in reverse_geocode_result[0]['geometry']:\n",
    "\n",
    "\n",
    "                        self.latitude = reverse_geocode_result[0]['geometry']['location']['lat']\n",
    "\n",
    "                        self.longitude = reverse_geocode_result[0]['geometry']['location']['lng']\n",
    "\n",
    "        else: \n",
    "\n",
    "            gmaps = googlemaps.Client(key=self.google_maps)\n",
    "\n",
    "            calle = self.adress\n",
    "\n",
    "\n",
    "            geocode_result = gmaps.geocode(str(calle))\n",
    "\n",
    "            if 'geometry' in geocode_result[0].keys(): \n",
    "\n",
    "                if 'location' in geocode_result[0]['geometry']:\n",
    "\n",
    "\n",
    "                    self.latitude = geocode_result[0]['geometry']['location']['lat']\n",
    "\n",
    "                    self.longitude = geocode_result[0]['geometry']['location']['lng']\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "                    #print('Tenemos info geolocalizada :)', '\\n')\n",
    "\n",
    "    # calculo de distancias a la estacion mas cercana\n",
    "\n",
    "    def distancias(self):\n",
    "  \n",
    "  \n",
    "        nuestro_terreno = [self.latitude, self.longitude]\n",
    "\n",
    "        distancia_a_campo = []\n",
    "\n",
    "\n",
    "        for ubicacion in range(self.estaciones_provincia.shape[0]):\n",
    "\n",
    "            latitud_ubicacion = self.estaciones_provincia.iloc[ubicacion, 1]\n",
    "            longitud_ubicacion = self.estaciones_provincia.iloc[ubicacion, 2]\n",
    "\n",
    "\n",
    "            ubicacion_estacion = [latitud_ubicacion, longitud_ubicacion]\n",
    "        #Creamos una lista que va a albergar los kms\n",
    "\n",
    "            \n",
    "\n",
    "            #Hacemos el calculo de las distancias, y lo añadimos al dataset\n",
    "            distancia_a_campo.append(geodesic(nuestro_terreno, ubicacion_estacion).km)\n",
    "        \n",
    "\n",
    "        self.estaciones_provincia['distancia'] = distancia_a_campo\n",
    "            \n",
    "\n",
    "        return self.estaciones_provincia\n",
    "\n",
    "\n",
    "    def ordenar_distancias(self, estaciones_provincia):\n",
    "\n",
    "\n",
    "        \n",
    "        #Ordenamos por distancia más cercana\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia.sort_values('distancia')\n",
    "\n",
    "        #Renombaramos los campos y nos quedamos con las columnas que queremos\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia.rename(columns={'latitud_of': 'Latitud', 'longitud_of': 'Longitud', 'distancia':'Distancia (KM)'})\n",
    "\n",
    "        estaciones_provincia['Distancia (KM)'] = estaciones_provincia['Distancia (KM)'].round(2)\n",
    "        estaciones_provincia[['Estacion','Latitud','Longitud','Distancia (KM)']]\n",
    "\n",
    "        #nos quedamos con la esatacion mas cercana\n",
    "\n",
    "        estacion = estaciones_provincia.iloc[0,0]\n",
    "\n",
    "\n",
    "        return estacion\n",
    "       \n",
    "       \n",
    "       # return self.estaciones\n",
    "\n",
    "    \n",
    "    #vamos a ver cuales son mis estaciones mas cercanas\n",
    "\n",
    "    def mis_estaciones_mas_cercanas(self, estaciones_provincia, estacion):\n",
    "        \n",
    "    #def mis_estaciones_mas_cercanas(self, estaciones_provincia, estacion):\n",
    "\n",
    "\n",
    "        #print(estaciones_provincia)\n",
    "\n",
    "\n",
    "        codigo_estacion_mas_cercana = estaciones_provincia[estaciones_provincia['Estacion'] == estacion][['indicativo']]\n",
    "\n",
    "        #codigo_estacion_mas_cercana = estaciones_provincia[estaciones_provincia['Estacion'] == self.estacion][['indicativo']]\n",
    "\n",
    "       # print(codigo_estacion_mas_cercana)\n",
    "\n",
    "        self.codigo_estacion_cercano = list(codigo_estacion_mas_cercana['indicativo'])[0]\n",
    "\n",
    "        #codigo_estacion_cercano = list(codigo_estacion_mas_cercana['indicativo'])[0]\n",
    "\n",
    "\n",
    "        return self.codigo_estacion_cercano\n",
    "\n",
    "        #return codigo_estacion_cercano\n",
    "\n",
    "\n",
    "    #obtenemos los datos de esa estacion: \n",
    "\n",
    "\n",
    "    def funciona_o_no(fecha_ini, fecha_fin, codigo, aemet):\n",
    "      \n",
    "      url = (\"https://opendata.aemet.es/opendata/api/valores/climatologicos/diarios/datos\"\n",
    "                \"/fechaini/{}T00:00:00UTC/fechafin/{}T00:00:00UTC/estacion/{}\".format(fecha_ini, fecha_fin, codigo))\n",
    "\n",
    "      API_KEY = aemet\n",
    "      querystring = {\"api_key\": API_KEY}\n",
    "          \n",
    "      r = requests.get(url, params=querystring, verify=False)\n",
    "\n",
    "      # print(r.json())\n",
    "\n",
    "\n",
    "      def parse_data(raw_data):\n",
    "          data = []\n",
    "          \n",
    "          for d in raw_data:\n",
    "              d = dict(d)  # Exto copia el parámetro\n",
    "              for param in ['prec', 'presMax', 'presMin', 'racha', 'sol', 'tmax', 'tmed', 'tmin', 'velmedia', 'altitud', 'dir']:\n",
    "                  try:\n",
    "                      d[param] = float(d[param].replace(',', '.'))\n",
    "                  except:\n",
    "                      d[param] = None\n",
    "\n",
    "              data.append(d)\n",
    "          return data\n",
    "\n",
    "      try:\n",
    "\n",
    "          #print(' El codigo en cuestion ', r.status_code)\n",
    "\n",
    "          print(r.json())\n",
    "\n",
    "          \n",
    "\n",
    "        \n",
    "\n",
    "          \n",
    "\n",
    "          if r.json()['estado'] == 200:\n",
    "\n",
    "              # print(r.json())\n",
    "\n",
    "              data_url = r.json()['datos']\n",
    "\n",
    "              return r.json()['estado']\n",
    "\n",
    "          elif r.json()['estado'] == 404:\n",
    "\n",
    "              return r.json()['estado']\n",
    "\n",
    "              #print('ERROR 404')\n",
    "\n",
    "              \n",
    "\n",
    "\n",
    "          else: \n",
    "\n",
    "              return r.json()['estado']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      except: \n",
    "\n",
    "          print('checkea las credenciales')\n",
    "\n",
    "\n",
    "    def meterelogia_estacion_mas_cercana(self):\n",
    "      \n",
    "        url = (\"https://opendata.aemet.es/opendata/api/valores/climatologicos/diarios/datos\"\n",
    "            \"/fechaini/{}T00:00:00UTC/fechafin/{}T00:00:00UTC/estacion/{}\".format(self.fecha_ini, self.fecha_fin, self.codigo_estacion_cercano))\n",
    "\n",
    "        API_KEY = self.aemet\n",
    "        querystring = {\"api_key\": API_KEY}\n",
    "            \n",
    "        r = requests.get(url, params=querystring, verify=False)\n",
    "\n",
    "       # print(r.json())\n",
    "\n",
    "\n",
    "        def parse_data(raw_data):\n",
    "            data = []\n",
    "            \n",
    "            for d in raw_data:\n",
    "                d = dict(d)  # Exto copia el parámetro\n",
    "                for param in ['prec', 'presMax', 'presMin', 'racha', 'sol', 'tmax', 'tmed', 'tmin', 'velmedia', 'altitud', 'dir']:\n",
    "                    try:\n",
    "                        d[param] = float(d[param].replace(',', '.'))\n",
    "                    except:\n",
    "                        d[param] = None\n",
    "\n",
    "                data.append(d)\n",
    "            return data\n",
    "\n",
    "        try:\n",
    "\n",
    "            print(' El codigo en cuestion ', r.status_code)\n",
    "\n",
    "            if r.status_code == 200:\n",
    "\n",
    "                #print(r.json())\n",
    "\n",
    "                data_url = r.json()['datos']\n",
    "\n",
    "                print('\\n La url que vamos a gestionar es: ', data_url, '\\n')\n",
    "\n",
    "                r_data = requests.get(data_url, params=querystring, verify=False)\n",
    "                #print(r_data)\n",
    "                #print('Y los datos son: ', r_data)\n",
    "                raw_data = r_data.json()\n",
    "                \n",
    "                raw_data = parse_data(raw_data)\n",
    "\n",
    "                #guardamos con los datos en el dataframe\n",
    "\n",
    "                información_base_cercana = pd.DataFrame(raw_data)\n",
    "\n",
    "                #print(información_base_cercana.head())\n",
    "\n",
    "\n",
    "                #return información_base_cercana\n",
    "\n",
    "        except: \n",
    "\n",
    "            #print('La extracción de información falla, checkea las credenciales')\n",
    "            a = 'EJECUTADOR DUMMY'\n",
    "\n",
    "            print(a)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #---------------- EXTRAEMOS LA INFORMACIÓN DE LAS DEMÁS ESTACIONES DE LA PROVINCIA\n",
    "        # \n",
    "        def busqueda_metricas_temperatura_media(nombre_estacion, codigo_estacion_cercano, fecha_ini, fecha_fin, diccionario, aemet_key):\n",
    "            \n",
    "\n",
    "        #0. Extraemos la información de una estación filtrando por el nombre de la estacion\n",
    "        #le añadimos el drop index, porque luego, más adelante reseeteamos el index para que el código funcione\n",
    "        #bien. Por loq ue, al genera un indice natural de python, el indice antiguo nos pasa como nueva columna y eso\n",
    "        #no nos intereesa. \n",
    "\n",
    "            #estacion_actual = estaciones_albacete[estaciones_albacete['Estacion'] == nombre_estacion].drop('index', axis = 1)\n",
    "\n",
    "            #codigo_estacion_mas_cercana = estaciones_provincia[estaciones_provincia['Estacion'] == estacion][['indicativo']]\n",
    "            #1. Nos qudamos con el código identificativo de la estacion de interes\n",
    "            \n",
    "            codigo_estacion_actual = codigo_estacion_cercano\n",
    "\n",
    "            # print(codigo_estacion_actual)\n",
    "\n",
    "            #2. Utilizamos el codigo de la estación para extraer la infomración metereológica\n",
    "\n",
    "            url = (\"https://opendata.aemet.es/opendata/api/valores/climatologicos/diarios/datos\"\n",
    "                \"/fechaini/{}T00:00:00UTC/fechafin/{}T00:00:00UTC/estacion/{}\".format(fecha_ini, fecha_fin,\\\n",
    "                                                                                        codigo_estacion_actual))\n",
    "\n",
    "            #API_KEY = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJraWdsZXNpYXNiYXJhaWJhckBzdHVkZW50LmVhZS5lcyIsImp0aSI6ImY4YWQ5OGRmLTkzMjQtNDEzMi05NjY3LTdjY2E2Nzc3Mzc0NiIsImlzcyI6IkFFTUVUIiwiaWF0IjoxNjQyOTYzODc0LCJ1c2VySWQiOiJmOGFkOThkZi05MzI0LTQxMzItOTY2Ny03Y2NhNjc3NzM3NDYiLCJyb2xlIjoiIn0.en7xw4HHYaZ4oW8qooX6wGG3yn1Tv3OzFfnhrZac6vo'\n",
    "\n",
    "            querystring = {\"api_key\": aemet_key}\n",
    "                \n",
    "            r = requests.get(url, params=querystring, verify=False)\n",
    "\n",
    "\n",
    "            if r.status_code == requests.codes.OK:\n",
    "                \n",
    "                #3. Nos qudamos con el apartado de 'datos' una vez transformada a json, que es una URL\n",
    "                #print(r.json())\n",
    "\n",
    "                data_url = r.json()['datos']\n",
    "\n",
    "                #4. Hacemos la petición a la API.\n",
    "\n",
    "                r_data = requests.get(data_url, params=querystring, verify=False)\n",
    "\n",
    "                #5. Hacemos la transfomración a JSON.\n",
    "\n",
    "                raw_data = r_data.json()\n",
    "\n",
    "                #6. Cambiamos los decimales de coma a punto\n",
    "\n",
    "                raw_data = parse_data(raw_data)\n",
    "                \n",
    "\n",
    "                #7. Guardamos el output en un dataframe\n",
    "\n",
    "                información_base_cercana_temp = pd.DataFrame(raw_data)\n",
    "\n",
    "                #8.Y nos quedamos con la ifnormación de la fecha y con la temperatura media de dicha estacion\n",
    "\n",
    "                información_temp_media = información_base_cercana_temp.loc[:,['fecha','tmed']]\n",
    "\n",
    "                #print('Los datos de esta estacion son: ', información_temp_media['tmed'].values.tolist()[:5])\n",
    "\n",
    "                #Finalmente, esta ifnormación la transladamos a lita para poder guardarlo junto al código de la estación de interés\n",
    "\n",
    "                diccionario[nombre_estacion] = información_temp_media['tmed'].values.tolist()\n",
    "\n",
    "            \n",
    "\n",
    "        '''\n",
    "        Dicho esto, creamos un diccionario para guardar la información de la formula que acabamos e crear, \n",
    "        y le pasamos la información de las estaciones de la provinica de interés. Pero para ello necesitamos saber cuales son \n",
    "        las estaciones de albacete\n",
    "\n",
    "        '''\n",
    "\n",
    "        url_estaciones = \"https://opendata.aemet.es/opendata/api/valores/climatologicos/inventarioestaciones/todasestaciones/\"\n",
    "        querystring = {\"api_key\":self.aemet}\n",
    "\n",
    "        headers = {\n",
    "            'cache-control': \"no-cache\"\n",
    "            }\n",
    "\n",
    "        #Como lo hemos hecho en veces anteriores, nos quedamos ocn el apartado de 'DATOS' que no deja de ser una URL. \n",
    "\n",
    "        #print(requests.request(\"GET\", url_estaciones, headers=headers, params=querystring))\n",
    "\n",
    "        print(json.loads(requests.request(\"GET\", url_estaciones, headers=headers, params=querystring).text))\n",
    "\n",
    "        datos_url_plu = json.loads(requests.request(\"GET\", url_estaciones, headers=headers, params=querystring).text)['datos']\n",
    "\n",
    "        #Hacemos la request, y los resultados los guardamos en un dataframe. \n",
    "\n",
    "        todas_estaciones = pd.DataFrame(requests.get(datos_url_plu, params=querystring, verify=False).json())\n",
    "\n",
    "        #Una vez que hemos logrado las estaciones filtramos por la provincia que nos interesa.\n",
    "\n",
    "        estaciones_albacete = todas_estaciones[todas_estaciones['provincia'] == 'ALBACETE'][['indicativo', 'latitud', 'nombre', 'longitud']]\n",
    "\n",
    "        #Una vez que tenemos las estaciones de la provincia accionamos la formula creada para obtener las temepraturas medias.\n",
    "\n",
    "\n",
    "        #restablecemos el índice para que cuente desde el 0 sino no va a funcionar el script\n",
    "\n",
    "        estaciones_albacete = estaciones_albacete.rename(columns={'nombre': 'Estacion'}).reset_index()\n",
    "        #print(estaciones_albacete)\n",
    "\n",
    "\n",
    "        #print(estaciones_albacete.loc[0,'Estacion'])\n",
    "\n",
    "\n",
    "\n",
    "        #estacioness = {}\n",
    "        estaciones = {}\n",
    "\n",
    "        for estac in range(0,estaciones_albacete.shape[0]):\n",
    "\n",
    "            #por cada estacion en la tabla de estaciones de esa provincia\n",
    "            #nos quedamos con el codigo de esa provincia: \n",
    "\n",
    "            nombre_estacion = estaciones_albacete.loc[estac,'Estacion']\n",
    "            #print(nombre_estacion)\n",
    "            busqueda_metricas_temperatura_media(nombre_estacion = nombre_estacion,\\\n",
    "             codigo_estacion_cercano = self.codigo_estacion_cercano,\\\n",
    "              fecha_ini = self.fecha_ini,\\\n",
    "               fecha_fin = self.fecha_fin ,\\\n",
    "                diccionario = estaciones,\\\n",
    "                aemet_key = self.aemet)\n",
    "\n",
    "            \n",
    "\n",
    "        #Transfomramos el output en un dataframe operativo\n",
    "\n",
    "        temperatura_media_estaciones = pd.DataFrame.from_dict(estaciones, orient='index').T\n",
    "\n",
    "        #si hay NAs los reemplazamos por 0\n",
    "\n",
    "\n",
    "        temperatura_media_estaciones = temperatura_media_estaciones.fillna(0)\n",
    "\n",
    "        #Creamos la columna de la media de las estaciones diarias\n",
    "\n",
    "        temperatura_media_estaciones['mean_tmed'] = temperatura_media_estaciones.mean(axis=1)\n",
    "\n",
    "\n",
    "        #Adjuntamos la fecha a la que se referencia cada media diaria\n",
    "\n",
    "        temperatura_media_estaciones['fecha'] = información_base_cercana['fecha']\n",
    "\n",
    "\n",
    "        #y nos quedamos solamente con los dos datos, la media diaria y la fecha\n",
    "\n",
    "        temperatura_media_estaciones = temperatura_media_estaciones[['fecha', 'mean_tmed']]\n",
    "\n",
    "        #---------------- JUNTAMOS LA INFORMACIÓN DE LAS DEMAS ESTACIONES OCN LA DE LA BASE AEREA\n",
    "\n",
    "        información_base_cercana['prov_tmed'] = temperatura_media_estaciones['mean_tmed']\n",
    "\n",
    "        #√emos el resultado del matching\n",
    "\n",
    "        #print(información_base_cercana.head())\n",
    "\n",
    "        #---------------- CREAMOS LAS NUEVAS METRICAS DE DATOS \n",
    "\n",
    "        '''\n",
    "        Si la temperatura exterior cae bajo los 7 grados, se sabe que el almendro puede empezar a caer en periodo de hibernación\n",
    "        Por lo que vamos a tener que investigar si este caso ocurre . \n",
    "        '''\n",
    "\n",
    "        import numpy as np\n",
    "\n",
    "        #primero nos interesa si ha estado dorido o no ha estado dormido\n",
    "\n",
    "        información_base_cercana['almendro_sueño'] = información_base_cercana['tmed'] < 7\n",
    "\n",
    "        #luego nos interesa saber a cuantos grados ha etado dormido si es true\n",
    "\n",
    "        información_base_cercana['dor_grados'] = 7 - información_base_cercana['tmed']\n",
    "\n",
    "        #solo queremos reperesentar los valores que ha estado realmente por debajo de 7 grados, por lo que\n",
    "        #todas aquellas veces que ha estado por encima, lo reemplazamos por 0. \n",
    "\n",
    "        información_base_cercana['dor_grados'] = np.where(información_base_cercana['dor_grados'] > 0,\\\n",
    "        información_base_cercana['dor_grados'], 0)\n",
    "\n",
    "\n",
    "        '''\n",
    "        En cuanto a la presión se refiere, también nos es de mucha interes porque es un medio que usan las \n",
    "        plantas para absorver la humedad de la tierra. \n",
    "        La presión interna tiene que ser superior a la externa. Nosotros de esta fuente solo tenemos la presión \n",
    "        externa, por lo que vamos a llamalo como tal. \n",
    "\n",
    "        '''\n",
    "\n",
    "        información_base_cercana['Presion_externa'] = (información_base_cercana['presMax'] + información_base_cercana['presMin'])/2\n",
    "\n",
    "        #--------------- CAMBIAMOS LOS NOMBRES DE LAS COLUMNAS \n",
    "\n",
    "\n",
    "        información_base_cercana = información_base_cercana[['fecha', 'nombre', \t'provincia','tmed','prec','tmin','tmax','dir','velmedia','presMax','presMin','prov_tmed','dor_grados', 'Presion_externa']]\n",
    "\n",
    "        #cambiamos los nombres de las columnas a otros más comprensibles\n",
    "\n",
    "        información_base_cercana = información_base_cercana.rename(columns={'nombre': 'Estacion', 'provincia': 'Provincia', 'tmed': 'Temperatura_media', 'prec':'Precipitacion_l_m3', 'tmin':'Temperatura_minima','tmax':'Temperatura_maxima','dir':'Direccion_viento','velmedia':'Velocidad_media','velmedia':'Velocidad_media','presMax':'Presion_maxima', 'presMin':'Presion_minima', 'prov_tmed':'Prom_temperatura_media_prov', 'dor_grados':'Grados_debajo_siete'})\n",
    "\n",
    "\n",
    "        return información_base_cercana\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJZWGZ5GsX7Z",
    "outputId": "62b2c712-45c8-4f70-f578-a32e09cdac04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in /home/bluetab/anaconda3/lib/python3.9/site-packages (1.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EGctW0rrsQKT"
   },
   "outputs": [],
   "source": [
    "\n",
    "#El objetivo de esta función es la construcción de una función que sirva para insertar \n",
    "#lineas en una tabla de sql.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "#import cryptography\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "------------------- AWS OLD CONNECTION --------------\n",
    "host = 'database-1.cq2dp4jmizro.eu-west-1.rds.amazonaws.com'\n",
    "user = 'admin'\n",
    "password = '12345678'\n",
    "database = 'GET_DATABASE'\n",
    "\n",
    "'''\n",
    "#----------------------- GCP connection-----------------\n",
    "\n",
    "host = '35.241.159.127' #este el el host nuevo\n",
    "user = 'admin'\n",
    "password = '12345678'\n",
    "database = 'GET_DATABASE'\n",
    "\n",
    "def insert_into(data, arrival_df):\n",
    "\n",
    "    #establecemos la conexión a la base de datos\n",
    "    connection = pymysql.connect(host=host,\n",
    "                             user=user,\n",
    "                             password=password,\n",
    "                             db=database)\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "\n",
    "    #especificamos cual es el nombre de la tabla destino\n",
    "\n",
    "    nombre_tabla = arrival_df\n",
    "\n",
    "    \n",
    "    # creating column list for insertion\n",
    "    cols = \"`,`\".join([str(i) for i in data.columns.tolist()])\n",
    "    cols = cols.strip()\n",
    "    # Insert DataFrame recrds one by one.\n",
    "    for i,row in data.iterrows():\n",
    "        sql = \"INSERT INTO `{}` (`\".format(nombre_tabla) +cols + \"`) VALUES (\" + \"%s,\"*(len(row)-1) + \"%s)\"\n",
    "\n",
    "            \n",
    "        cursor.execute(sql, tuple(row))\n",
    "\n",
    "            # the connection is not autocommitted by default, so we must commit to save our changes\n",
    "        connection.commit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esuxiVMQtBrU",
    "outputId": "1208d131-8808-4ce8-db92-91a576d437b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######################### \n",
      "\n",
      "Subiendo los datos del año;  2009\n",
      "Busqueda por coordenadas\n",
      "address_components\n",
      "address_components es una lista\n",
      "formatted_address\n",
      "formatted_address es una lista\n",
      "geometry\n",
      "geometry es una lista\n",
      "place_id\n",
      "place_id es una lista\n",
      "plus_code\n",
      "plus_code es una lista\n",
      "types\n",
      "types es una lista\n",
      "la provincia es:  Castile-La Mancha\n",
      "Tenemos info geolocalizada :) \n",
      " 39.55678330000001 ,  -3.1920417\n",
      " ... it is possible to extract the province information ...\n",
      " ... province obtained ...\n",
      " the province is: Toledo\n",
      "Provincia optenida :) \n",
      " TOLEDO\n",
      "['BARCELONA' 'GIRONA' 'TARRAGONA' 'A CORUÑA' 'ASTURIAS' 'BIZKAIA'\n",
      " 'CANTABRIA' 'GIPUZKOA' 'LEON' 'LUGO' 'NAVARRA' 'OURENSE' 'PONTEVEDRA'\n",
      " 'AVILA' 'BURGOS' 'MADRID' 'PALENCIA' 'SALAMANCA' 'SEGOVIA' 'SORIA'\n",
      " 'VALLADOLID' 'ZAMORA' 'CACERES' 'CUENCA' 'GUADALAJARA' 'TOLEDO' 'BADAJOZ'\n",
      " 'CIUDAD REAL' 'CORDOBA' 'HUELVA' 'CADIZ' 'CEUTA' 'GRANADA' 'JAEN'\n",
      " 'SEVILLA' 'ALMERIA' 'MALAGA' 'MELILLA' 'ALBACETE' 'ALICANTE' 'MURCIA'\n",
      " 'CASTELLON' 'TERUEL' 'VALENCIA' 'ARABA/ALAVA' 'HUESCA' 'LA RIOJA'\n",
      " 'LLEIDA' 'ZARAGOZA' 'ILLES BALEARS' 'LAS PALMAS' 'STA. CRUZ DE TENERIFE']\n",
      "                  Estacion  latitud_of  longitud_of indicativo\n",
      "0  SAN PABLO DE LOS MONTES   39.546944    -4.350556      3298X\n",
      "1     TALAVERA DE LA REINA   39.958611    -4.863611      3365A\n",
      "2        TOLEDO, LORENZANA   39.859444    -4.025556       3259\n",
      "3                   TOLEDO   39.884722    -4.045278      3260B\n",
      "4               MADRIDEJOS   39.491944    -3.528333       4067\n",
      "5    QUINTANAR DE LA ORDEN   39.597500    -3.046944      4061X\n",
      " El codigo en cuestion  200\n",
      "\n",
      " La url que vamos a gestionar es:  https://opendata.aemet.es/opendata/sh/4b63c977 \n",
      "\n",
      "        fecha               Estacion Provincia  Temperatura_media  \\\n",
      "0  2009-01-01  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "1  2009-01-02  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "2  2009-01-03  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "3  2009-01-04  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "4  2009-01-05  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "\n",
      "   Precipitacion_l_m3  Temperatura_minima  Temperatura_maxima  \\\n",
      "0                 0.0                 999                 999   \n",
      "1                 0.1                 999                 999   \n",
      "2                 7.7                 999                 999   \n",
      "3                 0.9                 999                 999   \n",
      "4                 0.0                 999                 999   \n",
      "\n",
      "   Direccion_viento  Velocidad_media  Presion_maxima  Presion_minima  \\\n",
      "0               999              999             999             999   \n",
      "1               999              999             999             999   \n",
      "2               999              999             999             999   \n",
      "3               999              999             999             999   \n",
      "4               999              999             999             999   \n",
      "\n",
      "   Prom_temperatura_media_prov  Grados_debajo_siete  Presion_externa  \n",
      "0                          0.0                    0              999  \n",
      "1                          0.0                    0              999  \n",
      "2                          0.0                    0              999  \n",
      "3                          0.0                    0              999  \n",
      "4                          0.0                    0              999  \n",
      "\n",
      " ######################### \n",
      "\n",
      "Subiendo los datos del año;  2010\n",
      "Busqueda por coordenadas\n",
      "address_components\n",
      "address_components es una lista\n",
      "formatted_address\n",
      "formatted_address es una lista\n",
      "geometry\n",
      "geometry es una lista\n",
      "place_id\n",
      "place_id es una lista\n",
      "plus_code\n",
      "plus_code es una lista\n",
      "types\n",
      "types es una lista\n",
      "la provincia es:  Castile-La Mancha\n",
      "Tenemos info geolocalizada :) \n",
      " 39.55678330000001 ,  -3.1920417\n",
      " ... it is possible to extract the province information ...\n",
      " ... province obtained ...\n",
      " the province is: Toledo\n",
      "Provincia optenida :) \n",
      " TOLEDO\n",
      "['BARCELONA' 'GIRONA' 'TARRAGONA' 'A CORUÑA' 'ASTURIAS' 'BIZKAIA'\n",
      " 'CANTABRIA' 'GIPUZKOA' 'LEON' 'LUGO' 'NAVARRA' 'OURENSE' 'PONTEVEDRA'\n",
      " 'AVILA' 'BURGOS' 'MADRID' 'PALENCIA' 'SALAMANCA' 'SEGOVIA' 'SORIA'\n",
      " 'VALLADOLID' 'ZAMORA' 'CACERES' 'CUENCA' 'GUADALAJARA' 'TOLEDO' 'BADAJOZ'\n",
      " 'CIUDAD REAL' 'CORDOBA' 'HUELVA' 'CADIZ' 'CEUTA' 'GRANADA' 'JAEN'\n",
      " 'SEVILLA' 'ALMERIA' 'MALAGA' 'MELILLA' 'ALBACETE' 'ALICANTE' 'MURCIA'\n",
      " 'CASTELLON' 'TERUEL' 'VALENCIA' 'ARABA/ALAVA' 'HUESCA' 'LA RIOJA'\n",
      " 'LLEIDA' 'ZARAGOZA' 'ILLES BALEARS' 'LAS PALMAS' 'STA. CRUZ DE TENERIFE']\n",
      "                  Estacion  latitud_of  longitud_of indicativo\n",
      "0  SAN PABLO DE LOS MONTES   39.546944    -4.350556      3298X\n",
      "1     TALAVERA DE LA REINA   39.958611    -4.863611      3365A\n",
      "2        TOLEDO, LORENZANA   39.859444    -4.025556       3259\n",
      "3                   TOLEDO   39.884722    -4.045278      3260B\n",
      "4               MADRIDEJOS   39.491944    -3.528333       4067\n",
      "5    QUINTANAR DE LA ORDEN   39.597500    -3.046944      4061X\n",
      " El codigo en cuestion  200\n",
      "\n",
      " La url que vamos a gestionar es:  https://opendata.aemet.es/opendata/sh/618f3f46 \n",
      "\n",
      "        fecha               Estacion Provincia  Temperatura_media  \\\n",
      "0  2010-01-09  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "1  2010-01-10  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "2  2010-01-14  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "3  2010-01-17  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "4  2010-01-18  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "\n",
      "   Precipitacion_l_m3  Temperatura_minima  Temperatura_maxima  \\\n",
      "0                 0.0                 999                 999   \n",
      "1                 8.7                 999                 999   \n",
      "2                 0.0                 999                 999   \n",
      "3                 0.0                 999                 999   \n",
      "4                 0.0                 999                 999   \n",
      "\n",
      "   Direccion_viento  Velocidad_media  Presion_maxima  Presion_minima  \\\n",
      "0               999              999             999             999   \n",
      "1               999              999             999             999   \n",
      "2               999              999             999             999   \n",
      "3               999              999             999             999   \n",
      "4               999              999             999             999   \n",
      "\n",
      "   Prom_temperatura_media_prov  Grados_debajo_siete  Presion_externa  \n",
      "0                          0.0                    0              999  \n",
      "1                          0.0                    0              999  \n",
      "2                          0.0                    0              999  \n",
      "3                          0.0                    0              999  \n",
      "4                          0.0                    0              999  \n",
      "\n",
      " ######################### \n",
      "\n",
      "Subiendo los datos del año;  2011\n",
      "Busqueda por coordenadas\n",
      "address_components\n",
      "address_components es una lista\n",
      "formatted_address\n",
      "formatted_address es una lista\n",
      "geometry\n",
      "geometry es una lista\n",
      "place_id\n",
      "place_id es una lista\n",
      "plus_code\n",
      "plus_code es una lista\n",
      "types\n",
      "types es una lista\n",
      "la provincia es:  Castile-La Mancha\n",
      "Tenemos info geolocalizada :) \n",
      " 39.55678330000001 ,  -3.1920417\n",
      " ... it is possible to extract the province information ...\n",
      " ... province obtained ...\n",
      " the province is: Toledo\n",
      "Provincia optenida :) \n",
      " TOLEDO\n",
      "['BARCELONA' 'GIRONA' 'TARRAGONA' 'A CORUÑA' 'ASTURIAS' 'BIZKAIA'\n",
      " 'CANTABRIA' 'GIPUZKOA' 'LEON' 'LUGO' 'NAVARRA' 'OURENSE' 'PONTEVEDRA'\n",
      " 'AVILA' 'BURGOS' 'MADRID' 'PALENCIA' 'SALAMANCA' 'SEGOVIA' 'SORIA'\n",
      " 'VALLADOLID' 'ZAMORA' 'CACERES' 'CUENCA' 'GUADALAJARA' 'TOLEDO' 'BADAJOZ'\n",
      " 'CIUDAD REAL' 'CORDOBA' 'HUELVA' 'CADIZ' 'CEUTA' 'GRANADA' 'JAEN'\n",
      " 'SEVILLA' 'ALMERIA' 'MALAGA' 'MELILLA' 'ALBACETE' 'ALICANTE' 'MURCIA'\n",
      " 'CASTELLON' 'TERUEL' 'VALENCIA' 'ARABA/ALAVA' 'HUESCA' 'LA RIOJA'\n",
      " 'LLEIDA' 'ZARAGOZA' 'ILLES BALEARS' 'LAS PALMAS' 'STA. CRUZ DE TENERIFE']\n",
      "                  Estacion  latitud_of  longitud_of indicativo\n",
      "0  SAN PABLO DE LOS MONTES   39.546944    -4.350556      3298X\n",
      "1     TALAVERA DE LA REINA   39.958611    -4.863611      3365A\n",
      "2        TOLEDO, LORENZANA   39.859444    -4.025556       3259\n",
      "3                   TOLEDO   39.884722    -4.045278      3260B\n",
      "4               MADRIDEJOS   39.491944    -3.528333       4067\n",
      "5    QUINTANAR DE LA ORDEN   39.597500    -3.046944      4061X\n",
      " El codigo en cuestion  200\n",
      "\n",
      " La url que vamos a gestionar es:  https://opendata.aemet.es/opendata/sh/85044947 \n",
      "\n",
      "        fecha               Estacion Provincia  Temperatura_media  \\\n",
      "0  2011-01-01  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "1  2011-01-02  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "2  2011-01-03  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "3  2011-01-04  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "4  2011-01-05  QUINTANAR DE LA ORDEN    TOLEDO                999   \n",
      "\n",
      "   Precipitacion_l_m3  Temperatura_minima  Temperatura_maxima  \\\n",
      "0                 0.0                 999                 999   \n",
      "1                 0.0                 999                 999   \n",
      "2                 0.0                 999                 999   \n",
      "3                 0.2                 999                 999   \n",
      "4                 1.8                 999                 999   \n",
      "\n",
      "   Direccion_viento  Velocidad_media  Presion_maxima  Presion_minima  \\\n",
      "0               999              999           999.0           999.0   \n",
      "1               999              999           999.0           999.0   \n",
      "2               999              999           999.0           999.0   \n",
      "3               999              999           999.0           999.0   \n",
      "4               999              999           999.0           999.0   \n",
      "\n",
      "   Prom_temperatura_media_prov  Grados_debajo_siete  Presion_externa  \n",
      "0                          0.0                    0            999.0  \n",
      "1                          0.0                    0            999.0  \n",
      "2                          0.0                    0            999.0  \n",
      "3                          0.0                    0            999.0  \n",
      "4                          0.0                    0            999.0  \n",
      "\n",
      " ######################### \n",
      "\n",
      "Subiendo los datos del año;  2012\n",
      "Busqueda por coordenadas\n",
      "address_components\n",
      "address_components es una lista\n",
      "formatted_address\n",
      "formatted_address es una lista\n",
      "geometry\n",
      "geometry es una lista\n",
      "place_id\n",
      "place_id es una lista\n",
      "plus_code\n",
      "plus_code es una lista\n",
      "types\n",
      "types es una lista\n",
      "la provincia es:  Castile-La Mancha\n",
      "Tenemos info geolocalizada :) \n",
      " 39.55678330000001 ,  -3.1920417\n",
      " ... it is possible to extract the province information ...\n",
      " ... province obtained ...\n",
      " the province is: Toledo\n",
      "Provincia optenida :) \n",
      " TOLEDO\n",
      "['BARCELONA' 'GIRONA' 'TARRAGONA' 'A CORUÑA' 'ASTURIAS' 'BIZKAIA'\n",
      " 'CANTABRIA' 'GIPUZKOA' 'LEON' 'LUGO' 'NAVARRA' 'OURENSE' 'PONTEVEDRA'\n",
      " 'AVILA' 'BURGOS' 'MADRID' 'PALENCIA' 'SALAMANCA' 'SEGOVIA' 'SORIA'\n",
      " 'VALLADOLID' 'ZAMORA' 'CACERES' 'CUENCA' 'GUADALAJARA' 'TOLEDO' 'BADAJOZ'\n",
      " 'CIUDAD REAL' 'CORDOBA' 'HUELVA' 'CADIZ' 'CEUTA' 'GRANADA' 'JAEN'\n",
      " 'SEVILLA' 'ALMERIA' 'MALAGA' 'MELILLA' 'ALBACETE' 'ALICANTE' 'MURCIA'\n",
      " 'CASTELLON' 'TERUEL' 'VALENCIA' 'ARABA/ALAVA' 'HUESCA' 'LA RIOJA'\n",
      " 'LLEIDA' 'ZARAGOZA' 'ILLES BALEARS' 'LAS PALMAS' 'STA. CRUZ DE TENERIFE']\n",
      "                  Estacion  latitud_of  longitud_of indicativo\n",
      "0  SAN PABLO DE LOS MONTES   39.546944    -4.350556      3298X\n",
      "1     TALAVERA DE LA REINA   39.958611    -4.863611      3365A\n",
      "2        TOLEDO, LORENZANA   39.859444    -4.025556       3259\n",
      "3                   TOLEDO   39.884722    -4.045278      3260B\n",
      "4               MADRIDEJOS   39.491944    -3.528333       4067\n",
      "5    QUINTANAR DE LA ORDEN   39.597500    -3.046944      4061X\n",
      " El codigo en cuestion  200\n",
      "\n",
      " La url que vamos a gestionar es:  https://opendata.aemet.es/opendata/sh/9d524e38 \n",
      "\n",
      "        fecha               Estacion Provincia  Temperatura_media  \\\n",
      "0  2012-01-26  QUINTANAR DE LA ORDEN    TOLEDO              999.0   \n",
      "1  2012-01-27  QUINTANAR DE LA ORDEN    TOLEDO              999.0   \n",
      "2  2012-01-28  QUINTANAR DE LA ORDEN    TOLEDO              999.0   \n",
      "3  2012-01-29  QUINTANAR DE LA ORDEN    TOLEDO              999.0   \n",
      "4  2012-01-30  QUINTANAR DE LA ORDEN    TOLEDO              999.0   \n",
      "\n",
      "   Precipitacion_l_m3  Temperatura_minima  Temperatura_maxima  \\\n",
      "0                 0.0               999.0               999.0   \n",
      "1                 0.2               999.0               999.0   \n",
      "2                 0.0               999.0               999.0   \n",
      "3                 0.0               999.0               999.0   \n",
      "4                 0.0               999.0               999.0   \n",
      "\n",
      "   Direccion_viento  Velocidad_media  Presion_maxima  Presion_minima  \\\n",
      "0             999.0            999.0           999.0           999.0   \n",
      "1             999.0            999.0           999.0           999.0   \n",
      "2             999.0            999.0           999.0           999.0   \n",
      "3             999.0            999.0           999.0           999.0   \n",
      "4             999.0            999.0           999.0           999.0   \n",
      "\n",
      "   Prom_temperatura_media_prov  Grados_debajo_siete  Presion_externa  \n",
      "0                          0.0                  0.0            999.0  \n",
      "1                          0.0                  0.0            999.0  \n",
      "2                          0.0                  0.0            999.0  \n",
      "3                          0.0                  0.0            999.0  \n",
      "4                          0.0                  0.0            999.0  \n",
      "\n",
      " ######################### \n",
      "\n",
      "Subiendo los datos del año;  2013\n",
      "Busqueda por coordenadas\n",
      "address_components\n",
      "address_components es una lista\n",
      "formatted_address\n",
      "formatted_address es una lista\n",
      "geometry\n",
      "geometry es una lista\n",
      "place_id\n",
      "place_id es una lista\n",
      "plus_code\n",
      "plus_code es una lista\n",
      "types\n",
      "types es una lista\n",
      "la provincia es:  Castile-La Mancha\n",
      "Tenemos info geolocalizada :) \n",
      " 39.55678330000001 ,  -3.1920417\n",
      " ... it is possible to extract the province information ...\n",
      " ... province obtained ...\n",
      " the province is: Toledo\n",
      "Provincia optenida :) \n",
      " TOLEDO\n",
      "['BARCELONA' 'GIRONA' 'TARRAGONA' 'A CORUÑA' 'ASTURIAS' 'BIZKAIA'\n",
      " 'CANTABRIA' 'GIPUZKOA' 'LEON' 'LUGO' 'NAVARRA' 'OURENSE' 'PONTEVEDRA'\n",
      " 'AVILA' 'BURGOS' 'MADRID' 'PALENCIA' 'SALAMANCA' 'SEGOVIA' 'SORIA'\n",
      " 'VALLADOLID' 'ZAMORA' 'CACERES' 'CUENCA' 'GUADALAJARA' 'TOLEDO' 'BADAJOZ'\n",
      " 'CIUDAD REAL' 'CORDOBA' 'HUELVA' 'CADIZ' 'CEUTA' 'GRANADA' 'JAEN'\n",
      " 'SEVILLA' 'ALMERIA' 'MALAGA' 'MELILLA' 'ALBACETE' 'ALICANTE' 'MURCIA'\n",
      " 'CASTELLON' 'TERUEL' 'VALENCIA' 'ARABA/ALAVA' 'HUESCA' 'LA RIOJA'\n",
      " 'LLEIDA' 'ZARAGOZA' 'ILLES BALEARS' 'LAS PALMAS' 'STA. CRUZ DE TENERIFE']\n",
      "                  Estacion  latitud_of  longitud_of indicativo\n",
      "0  SAN PABLO DE LOS MONTES   39.546944    -4.350556      3298X\n",
      "1     TALAVERA DE LA REINA   39.958611    -4.863611      3365A\n",
      "2        TOLEDO, LORENZANA   39.859444    -4.025556       3259\n",
      "3                   TOLEDO   39.884722    -4.045278      3260B\n",
      "4               MADRIDEJOS   39.491944    -3.528333       4067\n",
      "5    QUINTANAR DE LA ORDEN   39.597500    -3.046944      4061X\n",
      " El codigo en cuestion  200\n",
      "\n",
      " La url que vamos a gestionar es:  https://opendata.aemet.es/opendata/sh/32054b17 \n",
      "\n",
      "        fecha               Estacion Provincia  Temperatura_media  \\\n",
      "0  2013-01-25  QUINTANAR DE LA ORDEN    TOLEDO                5.2   \n",
      "1  2013-01-26  QUINTANAR DE LA ORDEN    TOLEDO               10.1   \n",
      "2  2013-01-27  QUINTANAR DE LA ORDEN    TOLEDO                8.2   \n",
      "3  2013-01-28  QUINTANAR DE LA ORDEN    TOLEDO                5.9   \n",
      "4  2013-01-29  QUINTANAR DE LA ORDEN    TOLEDO                6.0   \n",
      "\n",
      "   Precipitacion_l_m3  Temperatura_minima  Temperatura_maxima  \\\n",
      "0                 0.0                 0.9                 9.6   \n",
      "1                 0.1                 5.1                15.1   \n",
      "2                 5.7                 4.5                11.8   \n",
      "3                 0.0                 1.1                10.7   \n",
      "4                 0.0                -1.1                13.0   \n",
      "\n",
      "   Direccion_viento  Velocidad_media  Presion_maxima  Presion_minima  \\\n",
      "0              25.0              1.4           937.0           934.5   \n",
      "1              32.0              2.2           941.2           935.3   \n",
      "2              24.0              3.3           941.5           936.1   \n",
      "3              32.0              0.6           948.3           940.1   \n",
      "4              18.0              0.3           949.0           947.1   \n",
      "\n",
      "   Prom_temperatura_media_prov  Grados_debajo_siete  Presion_externa  \n",
      "0                          5.2                  1.8           935.75  \n",
      "1                         10.1                  0.0           938.25  \n",
      "2                          8.2                  0.0           938.80  \n",
      "3                          5.9                  1.1           944.20  \n",
      "4                          6.0                  1.0           948.05  \n",
      "\n",
      " ######################### \n",
      "\n",
      "Subiendo los datos del año;  2014\n",
      "Busqueda por coordenadas\n",
      "address_components\n",
      "address_components es una lista\n",
      "formatted_address\n",
      "formatted_address es una lista\n",
      "geometry\n",
      "geometry es una lista\n",
      "place_id\n",
      "place_id es una lista\n",
      "plus_code\n",
      "plus_code es una lista\n",
      "types\n",
      "types es una lista\n",
      "la provincia es:  Castile-La Mancha\n",
      "Tenemos info geolocalizada :) \n",
      " 39.55678330000001 ,  -3.1920417\n",
      " ... it is possible to extract the province information ...\n",
      " ... province obtained ...\n",
      " the province is: Toledo\n",
      "Provincia optenida :) \n",
      " TOLEDO\n",
      "['BARCELONA' 'GIRONA' 'TARRAGONA' 'A CORUÑA' 'ASTURIAS' 'BIZKAIA'\n",
      " 'CANTABRIA' 'GIPUZKOA' 'LEON' 'LUGO' 'NAVARRA' 'OURENSE' 'PONTEVEDRA'\n",
      " 'AVILA' 'BURGOS' 'MADRID' 'PALENCIA' 'SALAMANCA' 'SEGOVIA' 'SORIA'\n",
      " 'VALLADOLID' 'ZAMORA' 'CACERES' 'CUENCA' 'GUADALAJARA' 'TOLEDO' 'BADAJOZ'\n",
      " 'CIUDAD REAL' 'CORDOBA' 'HUELVA' 'CADIZ' 'CEUTA' 'GRANADA' 'JAEN'\n",
      " 'SEVILLA' 'ALMERIA' 'MALAGA' 'MELILLA' 'ALBACETE' 'ALICANTE' 'MURCIA'\n",
      " 'CASTELLON' 'TERUEL' 'VALENCIA' 'ARABA/ALAVA' 'HUESCA' 'LA RIOJA'\n",
      " 'LLEIDA' 'ZARAGOZA' 'ILLES BALEARS' 'LAS PALMAS' 'STA. CRUZ DE TENERIFE']\n",
      "                  Estacion  latitud_of  longitud_of indicativo\n",
      "0  SAN PABLO DE LOS MONTES   39.546944    -4.350556      3298X\n",
      "1     TALAVERA DE LA REINA   39.958611    -4.863611      3365A\n",
      "2        TOLEDO, LORENZANA   39.859444    -4.025556       3259\n",
      "3                   TOLEDO   39.884722    -4.045278      3260B\n",
      "4               MADRIDEJOS   39.491944    -3.528333       4067\n",
      "5    QUINTANAR DE LA ORDEN   39.597500    -3.046944      4061X\n",
      " El codigo en cuestion  200\n",
      "\n",
      " La url que vamos a gestionar es:  https://opendata.aemet.es/opendata/sh/5f7a5717 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'datos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m estacion_mas_cercana_codigo \u001b[38;5;241m=\u001b[39m mi_metereologia_clase\u001b[38;5;241m.\u001b[39mmis_estaciones_mas_cercanas(estaciones_provincia, estaciones_ordenadas)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m#print(estacion_mas_cercana_codigo)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m#hacer la llamada a la api de aemet\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m \n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m#print(mis_datos.head())\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mmi_metereologia_clase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeterelogia_estacion_mas_cercana\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m999\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mmi_metereologia.meterelogia_estacion_mas_cercana\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    668\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcache-control\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno-cache\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    670\u001b[0m     }\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m#Como lo hemos hecho en veces anteriores, nos quedamos ocn el apartado de 'DATOS' que no deja de ser una URL. \u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m#print(requests.request(\"GET\", url_estaciones, headers=headers, params=querystring))\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m#print(json.loads(requests.request(\"GET\", url_estaciones, headers=headers, params=querystring).text))\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m datos_url_plu \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl_estaciones\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquerystring\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;66;03m#Hacemos la request, y los resultados los guardamos en un dataframe. \u001b[39;00m\n\u001b[1;32m    682\u001b[0m todas_estaciones \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(requests\u001b[38;5;241m.\u001b[39mget(datos_url_plu, params\u001b[38;5;241m=\u001b[39mquerystring, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mjson())\n",
      "\u001b[0;31mKeyError\u001b[0m: 'datos'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import logging\n",
    "import requests\n",
    "import pymysql\n",
    "\n",
    "host = '34.175.164.167' #este el el host nuevo\n",
    "user = 'admin'\n",
    "password = '12345678'\n",
    "database = 'GET_DATABASE'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def conectame(host, user, password, database):\n",
    "\n",
    "    #conn = pymysql.connect(host=host, user=user, password=password, port=3306, db='GET_DATABASE',charset='utf8')\n",
    "\n",
    "    connection = pymysql.connect(host=host,\n",
    "                                user=user,\n",
    "                                password=password,\n",
    "                                db=database)\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    return cursor\n",
    "cursor = conectame(host, user, password, database)\n",
    "'''\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "try:\n",
    "    conn = pymysql.connect(host=host, user=user, passwd=password, db=database, connect_timeout=5)\n",
    "except pymysql.MySQLError as e:\n",
    "    logger.error(\"ERROR: Unexpected error: Could not connect to MySQL instance.\")\n",
    "    logger.error(e)\n",
    "    sys.exit()\n",
    "\n",
    "logger.info(\"SUCCESS: Connection to RDS MySQL instance succeeded\")\n",
    "\n",
    "#------------------ creamos la tabla ---------------\n",
    "\n",
    "def run_query(q):\n",
    "  with pymysql.connect(host=host,\n",
    "                             user=user,\n",
    "                             password=password,\n",
    "                             db=database) as conn:\n",
    "                             return pd.read_sql(q, conn)\n",
    "\n",
    "\n",
    "\n",
    "def checkTableExists(conn, tablename):\n",
    "    dbcur = conn.cursor()\n",
    "    dbcur.execute(\"\"\"\n",
    "        SELECT COUNT(*)\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_name = '{0}'\n",
    "        \"\"\".format(tablename.replace('\\'', '\\'\\'')))\n",
    "    if dbcur.fetchone()[0] == 1:\n",
    "        dbcur.close()\n",
    "        return True\n",
    "\n",
    "    dbcur.close()\n",
    "    return False\n",
    "\n",
    "#------------ ESPECIFICAMOS CUAL VA A SER LA TABLA DE INTERÉS------\n",
    "\n",
    "tabla_de_interes = 'METEREOLOGIA'\n",
    "\n",
    "coordenadas = (39.55678333333333, -3.1920416666666664) #https://www.vercalendario.info/es/como/convertir-latitud-longitud-grados-decimales.html#:~:text=Latitud%2038%C2%B054%E2%80%B2%2017%E2%80%B3N%20equivale%20a%2038.90472222222222%C2%B0,77.01638888888888%C2%B0%20(Grados%20decimales).\n",
    "\n",
    "API_AEMET = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJraWdsZXNpYXNiYXJhaWJhckBzdHVkZW50LmVhZS5lcyIsImp0aSI6ImY4YWQ5OGRmLTkzMjQtNDEzMi05NjY3LTdjY2E2Nzc3Mzc0NiIsImlzcyI6IkFFTUVUIiwiaWF0IjoxNjQyOTYzODc0LCJ1c2VySWQiOiJmOGFkOThkZi05MzI0LTQxMzItOTY2Ny03Y2NhNjc3NzM3NDYiLCJyb2xlIjoiIn0.en7xw4HHYaZ4oW8qooX6wGG3yn1Tv3OzFfnhrZac6vo'\n",
    "API_GOOGLE = 'AIzaSyD7zvwwj8-4JS2XZq0n8bLb9t2cSqStx84'\n",
    "\n",
    "if checkTableExists(conn, tabla_de_interes):\n",
    "    \n",
    "    for ano in range(2009, 2022):\n",
    "    \n",
    "        print('\\n ######################### \\n')\n",
    "\n",
    "        print('Subiendo los datos del año; ', ano)\n",
    "\n",
    "\n",
    "          #-------- HACEMOS EL SCRAPPING ----------\n",
    "\n",
    "\n",
    "        #ano = 1998\n",
    "\n",
    "        #df = mi_metereologia(8175, '{}-01-01'.format(ano), '{}-12-31'.format(ano), 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJraWdsZXNpYXNiYXJhaWJhckBzdHVkZW50LmVhZS5lcyIsImp0aSI6ImY4YWQ5OGRmLTkzMjQtNDEzMi05NjY3LTdjY2E2Nzc3Mzc0NiIsImlzcyI6IkFFTUVUIiwiaWF0IjoxNjQyOTYzODc0LCJ1c2VySWQiOiJmOGFkOThkZi05MzI0LTQxMzItOTY2Ny03Y2NhNjc3NzM3NDYiLCJyb2xlIjoiIn0.en7xw4HHYaZ4oW8qooX6wGG3yn1Tv3OzFfnhrZac6vo')\n",
    "\n",
    "          #Se reemplazan los nas por 999\n",
    "\n",
    "\n",
    "        mi_metereologia_clase = mi_metereologia( google_maps_key = API_GOOGLE,\\\n",
    "            coodenadas = coordenadas,\\\n",
    "            api_aemet =  API_AEMET,\\\n",
    "            fecha_ini = '{}-01-01'.format(ano),\\\n",
    "            fecha_fin = '{}-12-31'.format(ano))\n",
    "\n",
    "\n",
    "        #Sacamos que provincia me corresponde con la ubicacion que he pasado\n",
    "\n",
    "        provincia =  mi_metereologia_clase.address()\n",
    "\n",
    "\n",
    "\n",
    "        #Sacamos las esatciones de dicha provincia\n",
    "\n",
    "        estaciones_provincia = mi_metereologia_clase.estaciones()\n",
    "\n",
    "        print(estaciones_provincia)\n",
    "\n",
    "        #Extraigo mi latitud y longitud\n",
    "        mi_ubicacion = mi_metereologia_clase.mi_latlon()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #Sacamos la distancias que tengo a las estaciones de mi alrededor\n",
    "\n",
    "        mis_estaciones_distancias_brutas = mi_metereologia_clase.distancias()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #estaciones_provincia['distancia'] = mis_estaciones_distancias_brutas\n",
    "\n",
    "\n",
    "        #Falta sacar la estacion más cercana\n",
    "\n",
    "\n",
    "        estaciones_ordenadas = mi_metereologia_clase.ordenar_distancias(mis_estaciones_distancias_brutas)\n",
    "\n",
    "        estacion_mas_cercana_codigo = mi_metereologia_clase.mis_estaciones_mas_cercanas(estaciones_provincia, estaciones_ordenadas)\n",
    "\n",
    "\n",
    "        #print(estacion_mas_cercana_codigo)\n",
    "\n",
    "        #hacer la llamada a la api de aemet\n",
    "\n",
    "\n",
    "        #mis_datos = mi_metereologia_clase.meterelogia_estacion_mas_cercana()\n",
    "\n",
    "\n",
    "        #print(mis_datos.head())\n",
    "\n",
    "        df = mi_metereologia_clase.meterelogia_estacion_mas_cercana()\n",
    "\n",
    "        df = df.fillna(999)\n",
    "\n",
    "\n",
    "        print(df.head())\n",
    "          #print(df.head())\n",
    "\n",
    "\n",
    "          #-------- SUBIMOS LOS DATOS --------#\n",
    "\n",
    "        insert_into(df, 'METEREOLOGIA')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "  \n",
    "  \n",
    "else:\n",
    "    \n",
    "  q = '''CREATE TABLE METEREOLOGIA(\n",
    "\n",
    "    fecha   DATE NOT NULL, \n",
    "    Estacion VARCHAR(255) NOT NULL, \n",
    "    Provincia VARCHAR(255), \n",
    "    Temperatura_media INT,\n",
    "    Precipitacion_l_m3 INT, \n",
    "        Temperatura_minima float, \n",
    "        Temperatura_maxima float,\n",
    "        Direccion_viento VARCHAR(255), \n",
    "        Velocidad_media float, \n",
    "        Presion_maxima float,\n",
    "          Presion_minima float, \n",
    "          Prom_temperatura_media_prov float, \n",
    "          Grados_debajo_siete float,\n",
    "          Presion_externa float\n",
    "          \n",
    "          );'''\n",
    "\n",
    "\n",
    "  print(run_query(q))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n41Ov0kOJPss",
    "outputId": "92e820e8-12e2-43e3-f48b-5d0d93616704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 2.2 MB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: pymysql\n",
      "Successfully installed pymysql-1.0.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "b_5wGYcR5w38",
    "outputId": "4137d186-ab81-4dbf-cc5e-96b8a83da658"
   },
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nselect * from METEREOLOGIA;\n\n\n': (1146, \"Table 'GET_DATABASE.METEREOLOGIA' doesn't exist\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:2056\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2056\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2057\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymysql/cursors.py:148\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    146\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmogrify(query, args)\n\u001b[0;32m--> 148\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m query\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymysql/cursors.py:310\u001b[0m, in \u001b[0;36mCursor._query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_result()\n\u001b[0;32m--> 310\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_get_result()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymysql/connections.py:548\u001b[0m, in \u001b[0;36mConnection.query\u001b[0;34m(self, sql, unbuffered)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_command(COMMAND\u001b[38;5;241m.\u001b[39mCOM_QUERY, sql)\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_query_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43munbuffered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munbuffered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affected_rows\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymysql/connections.py:775\u001b[0m, in \u001b[0;36mConnection._read_query_result\u001b[0;34m(self, unbuffered)\u001b[0m\n\u001b[1;32m    774\u001b[0m     result \u001b[38;5;241m=\u001b[39m MySQLResult(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 775\u001b[0m     \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymysql/connections.py:1156\u001b[0m, in \u001b[0;36mMySQLResult.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1156\u001b[0m     first_packet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m first_packet\u001b[38;5;241m.\u001b[39mis_ok_packet():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymysql/connections.py:725\u001b[0m, in \u001b[0;36mConnection._read_packet\u001b[0;34m(self, packet_type)\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39munbuffered_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 725\u001b[0m     \u001b[43mpacket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymysql/protocol.py:221\u001b[0m, in \u001b[0;36mMysqlPacket.raise_for_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno =\u001b[39m\u001b[38;5;124m\"\u001b[39m, errno)\n\u001b[0;32m--> 221\u001b[0m \u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_mysql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pymysql/err.py:143\u001b[0m, in \u001b[0;36mraise_mysql_exception\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    142\u001b[0m     errorclass \u001b[38;5;241m=\u001b[39m InternalError \u001b[38;5;28;01mif\u001b[39;00m errno \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (1146, \"Table 'GET_DATABASE.METEREOLOGIA' doesn't exist\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m                              \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_sql(q, conn)\n\u001b[1;32m     50\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124mselect * from METEREOLOGIA;\u001b[39m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m---> 59\u001b[0m datos_mete \u001b[38;5;241m=\u001b[39m \u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m humedad_media_dia \u001b[38;5;241m=\u001b[39m  pd\u001b[38;5;241m.\u001b[39mpivot_table(datos_mete, values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTemperatura_media\u001b[39m\u001b[38;5;124m'\u001b[39m , index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     65\u001b[0m humedad_media_dia[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTemperatura_media\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mrun_query\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_query\u001b[39m(q):\n\u001b[1;32m     45\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m pymysql\u001b[38;5;241m.\u001b[39mconnect(host\u001b[38;5;241m=\u001b[39mhost,\n\u001b[1;32m     46\u001b[0m                              user\u001b[38;5;241m=\u001b[39muser,\n\u001b[1;32m     47\u001b[0m                              password\u001b[38;5;241m=\u001b[39mpassword,\n\u001b[1;32m     48\u001b[0m                              db\u001b[38;5;241m=\u001b[39mdatabase) \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[0;32m---> 49\u001b[0m                              \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:602\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    599\u001b[0m pandas_sql \u001b[38;5;241m=\u001b[39m pandasSQL_builder(con)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m--> 602\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    612\u001b[0m     _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:2116\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m   2104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2106\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2112\u001b[0m     dtype: DtypeArg \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2113\u001b[0m ):\n\u001b[1;32m   2115\u001b[0m     args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[0;32m-> 2116\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2117\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:2068\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2065\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2068\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\nselect * from METEREOLOGIA;\n\n\n': (1146, \"Table 'GET_DATABASE.METEREOLOGIA' doesn't exist\")"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "host = '34.175.164.167' #este el el host nuevo\n",
    "user = 'admin'\n",
    "password = '12345678'\n",
    "database = 'GET_DATABASE'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def conectame(host, user, password, database):\n",
    "\n",
    "    #conn = pymysql.connect(host=host, user=user, password=password, port=3306, db='GET_DATABASE',charset='utf8')\n",
    "\n",
    "    connection = pymysql.connect(host=host,\n",
    "                                user=user,\n",
    "                                password=password,\n",
    "                                db=database)\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    return cursor\n",
    "cursor = conectame(host, user, password, database)\n",
    "'''\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "try:\n",
    "    conn = pymysql.connect(host=host, user=user, passwd=password, db=database, connect_timeout=5)\n",
    "except pymysql.MySQLError as e:\n",
    "    logger.error(\"ERROR: Unexpected error: Could not connect to MySQL instance.\")\n",
    "    logger.error(e)\n",
    "    sys.exit()\n",
    "\n",
    "logger.info(\"SUCCESS: Connection to RDS MySQL instance succeeded\")\n",
    "\n",
    "def run_query(q):\n",
    "  with pymysql.connect(host=host,\n",
    "                             user=user,\n",
    "                             password=password,\n",
    "                             db=database) as conn:\n",
    "                             return pd.read_sql(q, conn)\n",
    "q = '''\n",
    "select * from METEREOLOGIA;\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datos_mete = run_query(q)\n",
    "\n",
    "humedad_media_dia =  pd.pivot_table(datos_mete, values='Temperatura_media' , index='fecha')\n",
    "\n",
    "\n",
    "    \n",
    "humedad_media_dia['Temperatura_media'].plot()\n",
    "plt.title('Evolución de la temperatura ')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrFHrw1pw4CP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNALKFWK/0rbhEOFqHtivXR",
   "include_colab_link": true,
   "name": "METEREOLOGIA_HISTORICO.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "e45ce66debf88b9cda824eb4cee1e0594db58cc01047f95e1e2ed016877e745e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
