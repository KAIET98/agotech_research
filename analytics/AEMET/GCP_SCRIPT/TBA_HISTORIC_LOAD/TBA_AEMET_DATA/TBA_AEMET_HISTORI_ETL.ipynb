{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/KAIET98/TFM_AGROTECH/blob/TBA_GOOGLE_FUNC/analytics/AEMET/GCP_SCRIPT/METEREOLOGIA_HISTORICO_TBA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzNfTrto1pW-"
   },
   "source": [
    "# Objetivo \n",
    "\n",
    "El objetivo de este script es el mismo que del METEREOLOGIA_HISTORICO de GCP_SCRIPT pero con la funcionalidad de código mejorada. Es decir, vamos a meter 22 años de historico de la finca de nuestros amigos de TBA. \n",
    "\n",
    "Con ello, vamos a obtener los datos de la estación metereológica más cercana y vamos a alimentar los datos que tenemos de ellos con los datos históricos. Así, podremos entrenar el algoritmo en mejores condiciones con más datos, como los datos de GET. \n",
    "\n",
    "\n",
    "En vez de correr el script que corrimos en su dia con GET, lo que vamos a correr es el script de 'metereologia_lat_lon_class.py' que también lo usamos el script otras funcionalidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACPad-lV2ogP"
   },
   "source": [
    "# Importamos el código "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ESz5Ci6n28UR",
    "outputId": "3cf23c7e-6228-4c31-ea3b-fd0d5309992b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googlemaps in /Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages (4.5.3)\n",
      "Requirement already satisfied: requests<3.0,>=2.20.0 in /Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages (from googlemaps) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.20.0->googlemaps) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.0.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mbu6I6rQ1mz0"
   },
   "outputs": [],
   "source": [
    "\n",
    "from pickle import NONE\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from geopy.distance import geodesic\n",
    "from folium import FeatureGroup \n",
    "import folium\n",
    "import googlemaps\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class mi_metereologia: \n",
    "\n",
    "    def __init__(self, informacion_adress  = None, google_maps_key = None, coodenadas = None, api_aemet = None):\n",
    "\n",
    "        self.adress =  informacion_adress\n",
    "\n",
    "        self.google_maps = google_maps_key\n",
    "\n",
    "        self.aemet = api_aemet\n",
    "\n",
    "        self.coordenadas = coodenadas\n",
    "\n",
    "        if self.coordenadas != None:\n",
    "\n",
    "            print('Busqueda por coordenadas')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    Obtenemos la provincia donde vive el usuario\n",
    "    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    def address(self):\n",
    "\n",
    "        \n",
    "        if self.coordenadas != None:\n",
    "\n",
    "            gmaps = googlemaps.Client(key=self.google_maps)\n",
    "\n",
    "            coordenadas = self.coordenadas\n",
    "\n",
    "            reverse_geocode_result = gmaps.reverse_geocode(coordenadas)\n",
    "\n",
    "\n",
    "            if 'long_name' in reverse_geocode_result[0]['address_components'][3]: \n",
    "\n",
    "                print('la provincia es: ', reverse_geocode_result[0]['address_components'][3]['long_name'])\n",
    "\n",
    "\n",
    "                self.resultado  = reverse_geocode_result[0]['address_components'][3]['long_name']\n",
    "\n",
    "\n",
    "                if 'geometry' in reverse_geocode_result[0].keys(): \n",
    "\n",
    "                    if 'location' in reverse_geocode_result[0]['geometry']:\n",
    "\n",
    "\n",
    "                        self.latitude = reverse_geocode_result[0]['geometry']['location']['lat']\n",
    "\n",
    "                        self.longitude = reverse_geocode_result[0]['geometry']['location']['lng']\n",
    "\n",
    "\n",
    "\n",
    "                        print('Tenemos info geolocalizada :)', '\\n', self.latitude , \", \", self.longitude)\n",
    "                    \n",
    "                    try: \n",
    "\n",
    "                        self.provincia = reverse_geocode_result[0]['address_components'][3]['long_name'].upper()\n",
    "\n",
    "                        print('Provincia optenida :)', '\\n', self.provincia )\n",
    "\n",
    "\n",
    "                    #Ejecutamos la función de visualización del mapa\n",
    "\n",
    "                    # mapa = ver_mapa(provincia)\n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    except: \n",
    "\n",
    "\n",
    "                        print('No se puede sacar la provincia')\n",
    "\n",
    "        \n",
    "        else:\n",
    "\n",
    "\n",
    "            gmaps = googlemaps.Client(key=self.google_maps)\n",
    "            \n",
    "            geocode_result = gmaps.geocode(str(self.adress))\n",
    "\n",
    "            if 'geometry' in geocode_result[0].keys(): \n",
    "\n",
    "                if 'location' in geocode_result[0]['geometry']:\n",
    "\n",
    "\n",
    "                    latitude = geocode_result[0]['geometry']['location']['lat']\n",
    "\n",
    "                    longitude = geocode_result[0]['geometry']['location']['lng']\n",
    "\n",
    "\n",
    "\n",
    "                    print('Tenemos info geolocalizada :)', '\\n')\n",
    "\n",
    "                try: \n",
    "\n",
    "                    self.provincia = geocode_result[0]['address_components'][3]['long_name'].upper()\n",
    "\n",
    "                    print('Provincia optenida :)', '\\n', self.provincia )\n",
    "\n",
    "\n",
    "                #Ejecutamos la función de visualización del mapa\n",
    "\n",
    "                # mapa = ver_mapa(provincia)\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "                except: \n",
    "\n",
    "\n",
    "                    print('No se puede sacar la provincia')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        #return mapa\n",
    "\n",
    "        return self.provincia\n",
    "\n",
    "\n",
    "\n",
    "    def estaciones(self): \n",
    "\n",
    "        #1. Primero sacamos cuale son las estaciones de españa\n",
    "\n",
    "\n",
    "        url = \"https://opendata.aemet.es/opendata/api/valores/climatologicos/inventarioestaciones/todasestaciones/\"\n",
    "\n",
    "        api_key = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJraWdsZXNpYXNiYXJhaWJhckBzdHVkZW50LmVhZS5lcyIsImp0aSI6ImY4YWQ5OGRmLTkzMjQtNDEzMi05NjY3LTdjY2E2Nzc3Mzc0NiIsImlzcyI6IkFFTUVUIiwiaWF0IjoxNjQyOTYzODc0LCJ1c2VySWQiOiJmOGFkOThkZi05MzI0LTQxMzItOTY2Ny03Y2NhNjc3NzM3NDYiLCJyb2xlIjoiIn0.en7xw4HHYaZ4oW8qooX6wGG3yn1Tv3OzFfnhrZac6vo'\n",
    "        querystring = {\"api_key\":api_key}\n",
    "\n",
    "        headers = {\n",
    "            'cache-control': \"no-cache\"\n",
    "            }\n",
    "\n",
    "        response = json.loads(requests.request(\"GET\", url, headers=headers, params=querystring).text)\n",
    "\n",
    "        if response['estado'] == requests.codes.OK:\n",
    "\n",
    "            #nos hacemos con el enlace\n",
    "            enlace  = json.loads(requests.request(\"GET\", url, headers=headers, params=querystring).text)['datos']\n",
    "\n",
    "            estaciones = pd.DataFrame(requests.get(enlace, params=querystring, verify=False).json())\n",
    "\n",
    "        \n",
    "        if self.provincia == 'VALENCIAN COMMUNITY':\n",
    "          \n",
    "          self.provincia = 'VALENCIA'\n",
    "\n",
    "        estaciones_provincia = estaciones[estaciones['provincia'] == self.provincia][['indicativo', 'latitud', 'nombre', 'longitud']]\n",
    "\n",
    "\n",
    "\n",
    "        #2. Filtramos las estaciones por la provincia que me corresponde como usuario\n",
    "\n",
    "\n",
    "        #modiifico laas columnas de latitud y longitud\n",
    "\n",
    "\n",
    "        estaciones_provincia['latitud_num_or']= estaciones_provincia.latitud.str.extract('(\\d+)')\n",
    "        estaciones_provincia['longitud_num_or']= estaciones_provincia.longitud.str.extract('(\\d+)')\n",
    "\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia[[\"indicativo\", \"nombre\", \"latitud_num_or\",  \"longitud_num_or\"]]\n",
    "\n",
    "\n",
    "        # cambiamos los nombres de las columnas\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia.rename(columns={'nombre': 'Estacion', 'latitud_num_or': 'Latitud', 'longitud_num_or': 'Longitud'})[['Estacion', \t'Latitud', \t'Longitud', 'indicativo']].reset_index().drop('index', axis = 1)\n",
    "\n",
    "        #definimos la lista donde guardaremos los resultados\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        Importamos las funciones de modificacion de datos de longitud latitud\n",
    "        \n",
    "        '''\n",
    "\n",
    "        def latitud_decimal(latitud_ini, lista):\n",
    "            \n",
    "            grados_lat = latitud_ini[:2]\n",
    "            min_lat = int(latitud_ini[2:4])/60\n",
    "            seg_lat = int(latitud_ini[4:6])/3600\n",
    "            latitud_decim = int(grados_lat)+min_lat+seg_lat\n",
    "            \n",
    "            #guardamos el resultado en una lista\n",
    "\n",
    "            lista.append(latitud_decim)\n",
    "\n",
    "\n",
    "\n",
    "        def longitud_decimal(longitud_ini, lista_lon):\n",
    "\n",
    "            grados_lon = longitud_ini[:2]\n",
    "            min_lon = int(longitud_ini[2:4])/60\n",
    "            seg_lon = int(longitud_ini[4:6])/3600\n",
    "            longitud_decim = -1*(int(grados_lon)+min_lon+seg_lon)\n",
    "\n",
    "            lista_lon.append(longitud_decim)\n",
    "\n",
    "\n",
    "\n",
    "        #0. Definimos las listas donde gaurdaremos los resultados de las localizacion\n",
    "        #es de las estaciones\n",
    "        latitudes = []\n",
    "        lista_longitudes = []\n",
    "\n",
    "        #print('El tamaño de esatciones_provincia es: ', len(estaciones_provincia))\n",
    "\n",
    "        #print(estaciones_provincia)\n",
    "\n",
    "        #Transformaeremos cada laittud y longitud qu eencontremos en el dataset \n",
    "        for linea in range(len(estaciones_provincia)):\n",
    "\n",
    "        #1. Luego definimos las funcioens para obtener los resutlados\n",
    "\n",
    "            latitud_decimal(estaciones_provincia.iloc[linea,1], latitudes)\n",
    "            longitud_decimal(estaciones_provincia.iloc[linea,2], lista_longitudes)\n",
    "\n",
    "\n",
    "        estaciones_provincia['latitud_of'] = latitudes\n",
    "\n",
    "        estaciones_provincia['longitud_of'] = lista_longitudes\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia[['Estacion', 'latitud_of', 'longitud_of', 'indicativo']]\n",
    "\n",
    "        self.estaciones_provincia = estaciones_provincia.rename(columns = {'latitud': 'latitud_of', 'longitud':'longitud_of'})\n",
    "\n",
    "        return self.estaciones_provincia\n",
    "        \n",
    "\n",
    "\n",
    "    #vemos cuales son mis estaciones mas cercanas\n",
    "\n",
    "\n",
    "    def mi_latlon(self):\n",
    "\n",
    "        self.addressgmaps = googlemaps.Client(key=self.google_maps)\n",
    "\n",
    "\n",
    "        if self.coordenadas != None:\n",
    "\n",
    "            \n",
    "\n",
    "            coordenadas = self.coordenadas\n",
    "            \n",
    "            reverse_geocode_result = self.addressgmaps.reverse_geocode(coordenadas)\n",
    "             \n",
    "\n",
    "           # print(reverse_geocode_result[0].keys())\n",
    "\n",
    "\n",
    "            if 'geometry' in reverse_geocode_result[0].keys(): \n",
    "\n",
    "                #print(reverse_geocode_result[0]['geometry'])\n",
    "\n",
    "                    if 'location' in reverse_geocode_result[0]['geometry']:\n",
    "\n",
    "\n",
    "                        self.latitude = reverse_geocode_result[0]['geometry']['location']['lat']\n",
    "\n",
    "                        self.longitude = reverse_geocode_result[0]['geometry']['location']['lng']\n",
    "\n",
    "        else: \n",
    "\n",
    "            gmaps = googlemaps.Client(key=self.google_maps)\n",
    "\n",
    "            calle = self.adress\n",
    "\n",
    "\n",
    "            geocode_result = gmaps.geocode(str(calle))\n",
    "\n",
    "            if 'geometry' in geocode_result[0].keys(): \n",
    "\n",
    "                if 'location' in geocode_result[0]['geometry']:\n",
    "\n",
    "\n",
    "                    self.latitude = geocode_result[0]['geometry']['location']['lat']\n",
    "\n",
    "                    self.longitude = geocode_result[0]['geometry']['location']['lng']\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "                    #print('Tenemos info geolocalizada :)', '\\n')\n",
    "\n",
    "    # calculo de distancias a la estacion mas cercana\n",
    "\n",
    "    def distancias(self):\n",
    "  \n",
    "  \n",
    "        nuestro_terreno = [self.latitude, self.longitude]\n",
    "\n",
    "        distancia_a_campo = []\n",
    "\n",
    "\n",
    "        for ubicacion in range(self.estaciones_provincia.shape[0]):\n",
    "\n",
    "            latitud_ubicacion = self.estaciones_provincia.iloc[ubicacion, 1]\n",
    "            longitud_ubicacion = self.estaciones_provincia.iloc[ubicacion, 2]\n",
    "\n",
    "\n",
    "            ubicacion_estacion = [latitud_ubicacion, longitud_ubicacion]\n",
    "        #Creamos una lista que va a albergar los kms\n",
    "\n",
    "            \n",
    "\n",
    "            #Hacemos el calculo de las distancias, y lo añadimos al dataset\n",
    "            distancia_a_campo.append(geodesic(nuestro_terreno, ubicacion_estacion).km)\n",
    "        \n",
    "\n",
    "        self.estaciones_provincia['distancia'] = distancia_a_campo\n",
    "            \n",
    "\n",
    "        return self.estaciones_provincia\n",
    "\n",
    "\n",
    "    def ordenar_distancias(self, estaciones_provincia):\n",
    "\n",
    "\n",
    "        \n",
    "        #Ordenamos por distancia más cercana\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia.sort_values('distancia')\n",
    "\n",
    "        #Renombaramos los campos y nos quedamos con las columnas que queremos\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia.rename(columns={'latitud_of': 'Latitud', 'longitud_of': 'Longitud', 'distancia':'Distancia (KM)'})\n",
    "\n",
    "        estaciones_provincia['Distancia (KM)'] = estaciones_provincia['Distancia (KM)'].round(2)\n",
    "        estaciones_provincia[['Estacion','Latitud','Longitud','Distancia (KM)']]\n",
    "\n",
    "        #nos quedamos con la esatacion mas cercana\n",
    "\n",
    "        estacion = estaciones_provincia.iloc[0,0]\n",
    "\n",
    "\n",
    "        return estacion\n",
    "       \n",
    "       \n",
    "       # return self.estaciones\n",
    "\n",
    "    \n",
    "    #vamos a ver cuales son mis estaciones mas cercanas\n",
    "\n",
    "    def mis_estaciones_mas_cercanas(self, estaciones_provincia, estacion):\n",
    "\n",
    "\n",
    "        #print(estaciones_provincia)\n",
    "\n",
    "\n",
    "        codigo_estacion_mas_cercana = estaciones_provincia[estaciones_provincia['Estacion'] == estacion][['indicativo']]\n",
    "\n",
    "       # print(codigo_estacion_mas_cercana)\n",
    "\n",
    "        self.codigo_estacion_cercano = list(codigo_estacion_mas_cercana['indicativo'])[0]\n",
    "\n",
    "        #codigo_estacion_cercano = list(codigo_estacion_mas_cercana['indicativo'])[0]\n",
    "\n",
    "\n",
    "        return self.codigo_estacion_cercano\n",
    "\n",
    "        #return codigo_estacion_cercano\n",
    "\n",
    "\n",
    "    #obtenemos los datos de esa estacion: \n",
    "\n",
    "    def meterelogia_estacion_mas_cercana(self, fecha_ini, fecha_fin):\n",
    "\n",
    "        \n",
    "        url = (\"https://opendata.aemet.es/opendata/api/valores/climatologicos/diarios/datos\"\n",
    "            \"/fechaini/{}T00:00:00UTC/fechafin/{}T00:00:00UTC/estacion/{}\".format(fecha_ini, fecha_fin, self.codigo_estacion_cercano))\n",
    "\n",
    "        API_KEY = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJraWdsZXNpYXNiYXJhaWJhckBzdHVkZW50LmVhZS5lcyIsImp0aSI6ImY4YWQ5OGRmLTkzMjQtNDEzMi05NjY3LTdjY2E2Nzc3Mzc0NiIsImlzcyI6IkFFTUVUIiwiaWF0IjoxNjQyOTYzODc0LCJ1c2VySWQiOiJmOGFkOThkZi05MzI0LTQxMzItOTY2Ny03Y2NhNjc3NzM3NDYiLCJyb2xlIjoiIn0.en7xw4HHYaZ4oW8qooX6wGG3yn1Tv3OzFfnhrZac6vo'\n",
    "\n",
    "\n",
    "        print('Buscando desde ', fecha_ini, ' hasta ', fecha_fin, '\\n ####################################### \\n' )\n",
    "\n",
    "        querystring = {\"api_key\": API_KEY}\n",
    "            \n",
    "        r = requests.get(url, params=querystring, verify=False)\n",
    "\n",
    "\n",
    "        def parse_data(raw_data):\n",
    "            data = []\n",
    "            \n",
    "            for d in raw_data:\n",
    "                d = dict(d)  # Exto copia el parámetro\n",
    "                for param in ['prec', 'presMax', 'presMin', 'racha', 'sol', 'tmax', 'tmed', 'tmin', 'velmedia', 'altitud', 'dir']:\n",
    "                    try:\n",
    "                        d[param] = float(d[param].replace(',', '.'))\n",
    "                    except:\n",
    "                        d[param] = None\n",
    "\n",
    "                data.append(d)\n",
    "            return data\n",
    "\n",
    "        try:\n",
    "\n",
    "            if r.status_code == requests.codes.OK:\n",
    "\n",
    "                print(r.json())\n",
    "\n",
    "                data_url = r.json()['datos']\n",
    "\n",
    "                print('\\n La url que vamos a gestionar es: ', data_url, '\\n')\n",
    "\n",
    "                r_data = requests.get(data_url, params=querystring, verify=False)\n",
    "\n",
    "                #print('Y los datos son: ', r_data)\n",
    "\n",
    "                raw_data = r_data.json()\n",
    "                \n",
    "                raw_data = parse_data(raw_data)\n",
    "\n",
    "                #guardamos con los datos en el dataframe\n",
    "\n",
    "                información_base_cercana = pd.DataFrame(raw_data)\n",
    "\n",
    "\n",
    "                return información_base_cercana\n",
    "\n",
    "        except: \n",
    "\n",
    "            print('La extracción de información falla, checkea las credenciales')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        #---------------- EXTRAEMOS LA INFORMACIÓN DE LAS DEMÁS ESTACIONES DE LA PROVINCIA\n",
    "        # \n",
    "        def busqueda_metricas_temperatura_media(self, nombre_estacion, diccionario):\n",
    "          \n",
    "          \n",
    "          #0. Extraemos la información de una estación filtrando por el nombre de la estacion\n",
    "        #le añadimos el drop index, porque luego, más adelante reseeteamos el index para que el código funcione\n",
    "        #bien. Por loq ue, al genera un indice natural de python, el indice antiguo nos pasa como nueva columna y eso\n",
    "        #no nos intereesa. \n",
    "\n",
    "            #estacion_actual = estaciones_albacete[estaciones_albacete['Estacion'] == nombre_estacion].drop('index', axis = 1)\n",
    "\n",
    "            #codigo_estacion_mas_cercana = estaciones_provincia[estaciones_provincia['Estacion'] == estacion][['indicativo']]\n",
    "            #1. Nos qudamos con el código identificativo de la estacion de interes\n",
    "            \n",
    "            codigo_estacion_actual = self.codigo_estacion_cercano\n",
    "\n",
    "            # print(codigo_estacion_actual)\n",
    "\n",
    "            #2. Utilizamos el codigo de la estación para extraer la infomración metereológica\n",
    "\n",
    "            url = (\"https://opendata.aemet.es/opendata/api/valores/climatologicos/diarios/datos\"\n",
    "                \"/fechaini/{}T00:00:00UTC/fechafin/{}T00:00:00UTC/estacion/{}\".format('2021-01-01', '2022-02-10',\\\n",
    "                                                                                        codigo_estacion_actual))\n",
    "\n",
    "            API_KEY = self.aemet\n",
    "            querystring = {\"api_key\": API_KEY}\n",
    "                \n",
    "            r = requests.get(url, params=querystring, verify=False)\n",
    "\n",
    "\n",
    "            if r.status_code == requests.codes.OK:\n",
    "              \n",
    "              print('REQUEST 200')\n",
    "               \n",
    "              print(r.json())\n",
    "\n",
    "              if r.json()['estado'] == 200:\n",
    "                \n",
    "                \n",
    "                #3. Nos qudamos con el apartado de 'datos' una vez transformada a json, que es una URL\n",
    "                #print(r.json())\n",
    "\n",
    "                data_url = r.json()['datos']\n",
    "\n",
    "                #4. Hacemos la petición a la API.\n",
    "\n",
    "                r_data = requests.get(data_url, params=querystring, verify=False)\n",
    "\n",
    "                #5. Hacemos la transfomración a JSON.\n",
    "\n",
    "                raw_data = r_data.json()\n",
    "\n",
    "                #6. Cambiamos los decimales de coma a punto\n",
    "\n",
    "                raw_data = parse_data(raw_data)\n",
    "                \n",
    "\n",
    "                #7. Guardamos el output en un dataframe\n",
    "\n",
    "                información_base_cercana_temp = pd.DataFrame(raw_data)\n",
    "\n",
    "                #8.Y nos quedamos con la ifnormación de la fecha y con la temperatura media de dicha estacion\n",
    "\n",
    "                información_temp_media = información_base_cercana_temp.loc[:,['fecha','tmed']]\n",
    "\n",
    "                #print('Los datos de esta estacion son: ', información_temp_media['tmed'].values.tolist()[:5])\n",
    "\n",
    "                #Finalmente, esta ifnormación la transladamos a lita para poder guardarlo junto al código de la estación de interés\n",
    "\n",
    "                diccionario[nombre_estacion] = información_temp_media['tmed'].values.tolist()\n",
    "              \n",
    "\n",
    "              elif r.json()['estado']  == 404:\n",
    "\n",
    "                print('Tenemos un error.')\n",
    "\n",
    "            \n",
    "\n",
    "        '''\n",
    "        Dicho esto, creamos un diccionario para guardar la información de la formula que acabamos e crear, \n",
    "        y le pasamos la información de las estaciones de la provinica de interés. Pero para ello necesitamos saber cuales son \n",
    "        las estaciones de albacete\n",
    "\n",
    "        '''\n",
    "\n",
    "        url_estaciones = \"https://opendata.aemet.es/opendata/api/valores/climatologicos/inventarioestaciones/todasestaciones/\"\n",
    "        querystring = {\"api_key\":self.aemet}\n",
    "\n",
    "        headers = {\n",
    "            'cache-control': \"no-cache\"\n",
    "            }\n",
    "\n",
    "        #Como lo hemos hecho en veces anteriores, nos quedamos ocn el apartado de 'DATOS' que no deja de ser una URL. \n",
    "\n",
    "        datos_url_plu = json.loads(requests.request(\"GET\", url_estaciones, headers=headers, params=querystring).text)['datos']\n",
    "\n",
    "        #Hacemos la request, y los resultados los guardamos en un dataframe. \n",
    "\n",
    "        todas_estaciones = pd.DataFrame(requests.get(datos_url_plu, params=querystring, verify=False).json())\n",
    "\n",
    "        #Una vez que hemos logrado las estaciones filtramos por la provincia que nos interesa.\n",
    "\n",
    "        estaciones_albacete = todas_estaciones[todas_estaciones['provincia'] == 'ALBACETE'][['indicativo', 'latitud', 'nombre', 'longitud']]\n",
    "\n",
    "        #Una vez que tenemos las estaciones de la provincia accionamos la formula creada para obtener las temepraturas medias.\n",
    "\n",
    "\n",
    "        #restablecemos el índice para que cuente desde el 0 sino no va a funcionar el script\n",
    "\n",
    "        estaciones_albacete = estaciones_albacete.rename(columns={'nombre': 'Estacion'}).reset_index()\n",
    "        #print(estaciones_albacete)\n",
    "\n",
    "\n",
    "        #print(estaciones_albacete.loc[0,'Estacion'])\n",
    "\n",
    "\n",
    "\n",
    "        estaciones = {}\n",
    "\n",
    "        for estac in range(0,estaciones_albacete.shape[0]):\n",
    "\n",
    "            #por cada estacion en la tabla de estaciones de esa provincia\n",
    "            #nos quedamos con el codigo de esa provincia: \n",
    "\n",
    "            nombre_estacion = estaciones_albacete.loc[estac,'Estacion']\n",
    "            #print(nombre_estacion)\n",
    "            busqueda_metricas_temperatura_media(nombre_estacion, estaciones)\n",
    "\n",
    "\n",
    "        #Transfomramos el output en un dataframe operativo\n",
    "\n",
    "        temperatura_media_estaciones = pd.DataFrame.from_dict(estaciones, orient='index').T\n",
    "\n",
    "        #si hay NAs los reemplazamos por 0\n",
    "\n",
    "\n",
    "        temperatura_media_estaciones = temperatura_media_estaciones.fillna(0)\n",
    "\n",
    "        #Creamos la columna de la media de las estaciones diarias\n",
    "\n",
    "        temperatura_media_estaciones['mean_tmed'] = temperatura_media_estaciones.mean(axis=1)\n",
    "\n",
    "\n",
    "        #Adjuntamos la fecha a la que se referencia cada media diaria\n",
    "\n",
    "        temperatura_media_estaciones['fecha'] = información_base_cercana['fecha']\n",
    "\n",
    "\n",
    "        #y nos quedamos solamente con los dos datos, la media diaria y la fecha\n",
    "\n",
    "        temperatura_media_estaciones = temperatura_media_estaciones[['fecha', 'mean_tmed']]\n",
    "\n",
    "        #---------------- JUNTAMOS LA INFORMACIÓN DE LAS DEMAS ESTACIONES OCN LA DE LA BASE AEREA\n",
    "\n",
    "        información_base_cercana['prov_tmed'] = temperatura_media_estaciones['mean_tmed']\n",
    "\n",
    "        #√emos el resultado del matching\n",
    "\n",
    "        #print(información_base_cercana.head())\n",
    "\n",
    "        #---------------- CREAMOS LAS NUEVAS METRICAS DE DATOS \n",
    "\n",
    "        '''\n",
    "        Si la temperatura exterior cae bajo los 7 grados, se sabe que el almendro puede empezar a caer en periodo de hibernación\n",
    "        Por lo que vamos a tener que investigar si este caso ocurre . \n",
    "        '''\n",
    "\n",
    "        import numpy as np\n",
    "\n",
    "        #primero nos interesa si ha estado dorido o no ha estado dormido\n",
    "\n",
    "        información_base_cercana['almendro_sueño'] = información_base_cercana['tmed'] < 7\n",
    "\n",
    "        #luego nos interesa saber a cuantos grados ha etado dormido si es true\n",
    "\n",
    "        información_base_cercana['dor_grados'] = 7 - información_base_cercana['tmed']\n",
    "\n",
    "        #solo queremos reperesentar los valores que ha estado realmente por debajo de 7 grados, por lo que\n",
    "        #todas aquellas veces que ha estado por encima, lo reemplazamos por 0. \n",
    "\n",
    "        información_base_cercana['dor_grados'] = np.where(información_base_cercana['dor_grados'] > 0,\\\n",
    "          información_base_cercana['dor_grados'], 0)\n",
    "\n",
    "\n",
    "        '''\n",
    "        En cuanto a la presión se refiere, también nos es de mucha interes porque es un medio que usan las \n",
    "        plantas para absorver la humedad de la tierra. \n",
    "        La presión interna tiene que ser superior a la externa. Nosotros de esta fuente solo tenemos la presión \n",
    "        externa, por lo que vamos a llamalo como tal. \n",
    "\n",
    "        '''\n",
    "\n",
    "        información_base_cercana['Presion_externa'] = (información_base_cercana['presMax'] + información_base_cercana['presMin'])/2\n",
    "\n",
    "        #--------------- CAMBIAMOS LOS NOMBRES DE LAS COLUMNAS \n",
    "\n",
    "\n",
    "        información_base_cercana = información_base_cercana[['fecha', 'nombre', \t'provincia','tmed','prec','tmin','tmax','dir','velmedia','presMax','presMin','prov_tmed','dor_grados', 'Presion_externa']]\n",
    "\n",
    "        #cambiamos los nombres de las columnas a otros más comprensibles\n",
    "\n",
    "        información_base_cercana = información_base_cercana.rename(columns={'nombre': 'Estacion', 'provincia': 'Provincia', 'tmed': 'Temperatura_media', 'prec':'Precipitacion_l_m3', 'tmin':'Temperatura_minima','tmax':'Temperatura_maxima','dir':'Direccion_viento','velmedia':'Velocidad_media','velmedia':'Velocidad_media','presMax':'Presion_maxima', 'presMin':'Presion_minima', 'prov_tmed':'Prom_temperatura_media_prov', 'dor_grados':'Grados_debajo_siete'})\n",
    "\n",
    "\n",
    "        return información_base_cercana\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSc9_t4M2wMr"
   },
   "source": [
    "# Realizamos ciertas modificaciones\n",
    "\n",
    "Son modificaciones por si no existen datos de cierta naturaleza en la llamada de la API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TyRULEH6jmsj",
    "outputId": "405ddca0-b566-4c73-86e9-16aa47cc45a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googlemaps in /Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages (4.5.3)\n",
      "Requirement already satisfied: requests<3.0,>=2.20.0 in /Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages (from googlemaps) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.20.0->googlemaps) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OkUvjn9u2rMD"
   },
   "outputs": [],
   "source": [
    "\n",
    "from pickle import NONE\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from geopy.distance import geodesic\n",
    "from folium import FeatureGroup \n",
    "import folium\n",
    "import googlemaps\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class mi_metereologia: \n",
    "\n",
    "    def __init__(self, informacion_adress  = None, google_maps_key = None, coodenadas = None, api_aemet = None):\n",
    "\n",
    "        self.adress =  informacion_adress\n",
    "\n",
    "        self.google_maps = google_maps_key\n",
    "\n",
    "        self.aemet = api_aemet\n",
    "\n",
    "        self.coordenadas = coodenadas\n",
    "\n",
    "        if self.coordenadas != None:\n",
    "\n",
    "            print('Busqueda por coordenadas')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    Obtenemos la provincia donde vive el usuario\n",
    "    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    def address(self):\n",
    "\n",
    "        \n",
    "        if self.coordenadas != None:\n",
    "\n",
    "            gmaps = googlemaps.Client(key=self.google_maps)\n",
    "\n",
    "            coordenadas = self.coordenadas\n",
    "\n",
    "            reverse_geocode_result = gmaps.reverse_geocode(coordenadas)\n",
    "\n",
    "\n",
    "            if 'long_name' in reverse_geocode_result[0]['address_components'][3]: \n",
    "\n",
    "                print('la provincia es: ', reverse_geocode_result[0]['address_components'][3]['long_name'])\n",
    "\n",
    "\n",
    "                self.resultado  = reverse_geocode_result[0]['address_components'][3]['long_name']\n",
    "\n",
    "\n",
    "                if 'geometry' in reverse_geocode_result[0].keys(): \n",
    "\n",
    "                    if 'location' in reverse_geocode_result[0]['geometry']:\n",
    "\n",
    "\n",
    "                        self.latitude = reverse_geocode_result[0]['geometry']['location']['lat']\n",
    "\n",
    "                        self.longitude = reverse_geocode_result[0]['geometry']['location']['lng']\n",
    "\n",
    "\n",
    "\n",
    "                        print('Tenemos info geolocalizada :)', '\\n', self.latitude , \", \", self.longitude)\n",
    "                    \n",
    "                    try: \n",
    "\n",
    "                        self.provincia = reverse_geocode_result[0]['address_components'][3]['long_name'].upper()\n",
    "\n",
    "                        print('Provincia optenida :)', '\\n', self.provincia )\n",
    "\n",
    "\n",
    "                    #Ejecutamos la función de visualización del mapa\n",
    "\n",
    "                    # mapa = ver_mapa(provincia)\n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    except: \n",
    "\n",
    "\n",
    "                        print('No se puede sacar la provincia')\n",
    "\n",
    "        \n",
    "        else:\n",
    "\n",
    "\n",
    "            gmaps = googlemaps.Client(key=self.google_maps)\n",
    "            \n",
    "            geocode_result = gmaps.geocode(str(self.adress))\n",
    "\n",
    "            if 'geometry' in geocode_result[0].keys(): \n",
    "\n",
    "                if 'location' in geocode_result[0]['geometry']:\n",
    "\n",
    "\n",
    "                    latitude = geocode_result[0]['geometry']['location']['lat']\n",
    "\n",
    "                    longitude = geocode_result[0]['geometry']['location']['lng']\n",
    "\n",
    "\n",
    "\n",
    "                    print('Tenemos info geolocalizada :)', '\\n')\n",
    "\n",
    "                try: \n",
    "\n",
    "                    self.provincia = geocode_result[0]['address_components'][3]['long_name'].upper()\n",
    "\n",
    "                    print('Provincia optenida :)', '\\n', self.provincia )\n",
    "\n",
    "\n",
    "                #Ejecutamos la función de visualización del mapa\n",
    "\n",
    "                # mapa = ver_mapa(provincia)\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "                except: \n",
    "\n",
    "\n",
    "                    print('No se puede sacar la provincia')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        #return mapa\n",
    "\n",
    "        return self.provincia\n",
    "\n",
    "\n",
    "\n",
    "    def estaciones(self): \n",
    "\n",
    "        #1. Primero sacamos cuale son las estaciones de españa\n",
    "\n",
    "\n",
    "        url = \"https://opendata.aemet.es/opendata/api/valores/climatologicos/inventarioestaciones/todasestaciones/\"\n",
    "\n",
    "        api_key = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJraWdsZXNpYXNiYXJhaWJhckBzdHVkZW50LmVhZS5lcyIsImp0aSI6ImY4YWQ5OGRmLTkzMjQtNDEzMi05NjY3LTdjY2E2Nzc3Mzc0NiIsImlzcyI6IkFFTUVUIiwiaWF0IjoxNjQyOTYzODc0LCJ1c2VySWQiOiJmOGFkOThkZi05MzI0LTQxMzItOTY2Ny03Y2NhNjc3NzM3NDYiLCJyb2xlIjoiIn0.en7xw4HHYaZ4oW8qooX6wGG3yn1Tv3OzFfnhrZac6vo'\n",
    "        querystring = {\"api_key\":api_key}\n",
    "\n",
    "        headers = {\n",
    "            'cache-control': \"no-cache\"\n",
    "            }\n",
    "\n",
    "        response = json.loads(requests.request(\"GET\", url, headers=headers, params=querystring).text)\n",
    "\n",
    "        if response['estado'] == requests.codes.OK:\n",
    "\n",
    "            #nos hacemos con el enlace\n",
    "            enlace  = json.loads(requests.request(\"GET\", url, headers=headers, params=querystring).text)['datos']\n",
    "\n",
    "            estaciones = pd.DataFrame(requests.get(enlace, params=querystring, verify=False).json())\n",
    "\n",
    "        \n",
    "        if self.provincia == 'VALENCIAN COMMUNITY':\n",
    "          \n",
    "          self.provincia = 'VALENCIA'\n",
    "\n",
    "        estaciones_provincia = estaciones[estaciones['provincia'] == self.provincia][['indicativo', 'latitud', 'nombre', 'longitud']]\n",
    "\n",
    "\n",
    "\n",
    "        #2. Filtramos las estaciones por la provincia que me corresponde como usuario\n",
    "\n",
    "\n",
    "        #modiifico laas columnas de latitud y longitud\n",
    "\n",
    "\n",
    "        estaciones_provincia['latitud_num_or']= estaciones_provincia.latitud.str.extract('(\\d+)')\n",
    "        estaciones_provincia['longitud_num_or']= estaciones_provincia.longitud.str.extract('(\\d+)')\n",
    "\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia[[\"indicativo\", \"nombre\", \"latitud_num_or\",  \"longitud_num_or\"]]\n",
    "\n",
    "\n",
    "        # cambiamos los nombres de las columnas\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia.rename(columns={'nombre': 'Estacion', 'latitud_num_or': 'Latitud', 'longitud_num_or': 'Longitud'})[['Estacion', \t'Latitud', \t'Longitud', 'indicativo']].reset_index().drop('index', axis = 1)\n",
    "\n",
    "        #definimos la lista donde guardaremos los resultados\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        Importamos las funciones de modificacion de datos de longitud latitud\n",
    "        \n",
    "        '''\n",
    "\n",
    "        def latitud_decimal(latitud_ini, lista):\n",
    "            \n",
    "            grados_lat = latitud_ini[:2]\n",
    "            min_lat = int(latitud_ini[2:4])/60\n",
    "            seg_lat = int(latitud_ini[4:6])/3600\n",
    "            latitud_decim = int(grados_lat)+min_lat+seg_lat\n",
    "            \n",
    "            #guardamos el resultado en una lista\n",
    "\n",
    "            lista.append(latitud_decim)\n",
    "\n",
    "\n",
    "\n",
    "        def longitud_decimal(longitud_ini, lista_lon):\n",
    "\n",
    "            grados_lon = longitud_ini[:2]\n",
    "            min_lon = int(longitud_ini[2:4])/60\n",
    "            seg_lon = int(longitud_ini[4:6])/3600\n",
    "            longitud_decim = -1*(int(grados_lon)+min_lon+seg_lon)\n",
    "\n",
    "            lista_lon.append(longitud_decim)\n",
    "\n",
    "\n",
    "\n",
    "        #0. Definimos las listas donde gaurdaremos los resultados de las localizacion\n",
    "        #es de las estaciones\n",
    "        latitudes = []\n",
    "        lista_longitudes = []\n",
    "\n",
    "        #print('El tamaño de esatciones_provincia es: ', len(estaciones_provincia))\n",
    "\n",
    "        #print(estaciones_provincia)\n",
    "\n",
    "        #Transformaeremos cada laittud y longitud qu eencontremos en el dataset \n",
    "        for linea in range(len(estaciones_provincia)):\n",
    "\n",
    "        #1. Luego definimos las funcioens para obtener los resutlados\n",
    "\n",
    "            latitud_decimal(estaciones_provincia.iloc[linea,1], latitudes)\n",
    "            longitud_decimal(estaciones_provincia.iloc[linea,2], lista_longitudes)\n",
    "\n",
    "\n",
    "        estaciones_provincia['latitud_of'] = latitudes\n",
    "\n",
    "        estaciones_provincia['longitud_of'] = lista_longitudes\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia[['Estacion', 'latitud_of', 'longitud_of', 'indicativo']]\n",
    "\n",
    "        self.estaciones_provincia = estaciones_provincia.rename(columns = {'latitud': 'latitud_of', 'longitud':'longitud_of'})\n",
    "\n",
    "        return self.estaciones_provincia\n",
    "        \n",
    "\n",
    "\n",
    "    #vemos cuales son mis estaciones mas cercanas\n",
    "\n",
    "\n",
    "    def mi_latlon(self):\n",
    "\n",
    "        self.addressgmaps = googlemaps.Client(key=self.google_maps)\n",
    "\n",
    "\n",
    "        if self.coordenadas != None:\n",
    "\n",
    "            \n",
    "\n",
    "            coordenadas = self.coordenadas\n",
    "            \n",
    "            reverse_geocode_result = self.addressgmaps.reverse_geocode(coordenadas)\n",
    "             \n",
    "\n",
    "           # print(reverse_geocode_result[0].keys())\n",
    "\n",
    "\n",
    "            if 'geometry' in reverse_geocode_result[0].keys(): \n",
    "\n",
    "                #print(reverse_geocode_result[0]['geometry'])\n",
    "\n",
    "                    if 'location' in reverse_geocode_result[0]['geometry']:\n",
    "\n",
    "\n",
    "                        self.latitude = reverse_geocode_result[0]['geometry']['location']['lat']\n",
    "\n",
    "                        self.longitude = reverse_geocode_result[0]['geometry']['location']['lng']\n",
    "\n",
    "        else: \n",
    "\n",
    "            gmaps = googlemaps.Client(key=self.google_maps)\n",
    "\n",
    "            calle = self.adress\n",
    "\n",
    "\n",
    "            geocode_result = gmaps.geocode(str(calle))\n",
    "\n",
    "            if 'geometry' in geocode_result[0].keys(): \n",
    "\n",
    "                if 'location' in geocode_result[0]['geometry']:\n",
    "\n",
    "\n",
    "                    self.latitude = geocode_result[0]['geometry']['location']['lat']\n",
    "\n",
    "                    self.longitude = geocode_result[0]['geometry']['location']['lng']\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "                    #print('Tenemos info geolocalizada :)', '\\n')\n",
    "\n",
    "    # calculo de distancias a la estacion mas cercana\n",
    "\n",
    "    def distancias(self):\n",
    "  \n",
    "  \n",
    "        nuestro_terreno = [self.latitude, self.longitude]\n",
    "\n",
    "        distancia_a_campo = []\n",
    "\n",
    "\n",
    "        for ubicacion in range(self.estaciones_provincia.shape[0]):\n",
    "\n",
    "            latitud_ubicacion = self.estaciones_provincia.iloc[ubicacion, 1]\n",
    "            longitud_ubicacion = self.estaciones_provincia.iloc[ubicacion, 2]\n",
    "\n",
    "\n",
    "            ubicacion_estacion = [latitud_ubicacion, longitud_ubicacion]\n",
    "        #Creamos una lista que va a albergar los kms\n",
    "\n",
    "            \n",
    "\n",
    "            #Hacemos el calculo de las distancias, y lo añadimos al dataset\n",
    "            distancia_a_campo.append(geodesic(nuestro_terreno, ubicacion_estacion).km)\n",
    "        \n",
    "\n",
    "        self.estaciones_provincia['distancia'] = distancia_a_campo\n",
    "            \n",
    "\n",
    "        return self.estaciones_provincia\n",
    "\n",
    "\n",
    "    def ordenar_distancias(self, estaciones_provincia):\n",
    "\n",
    "\n",
    "        \n",
    "        #Ordenamos por distancia más cercana\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia.sort_values('distancia')\n",
    "\n",
    "        #Renombaramos los campos y nos quedamos con las columnas que queremos\n",
    "\n",
    "        estaciones_provincia = estaciones_provincia.rename(columns={'latitud_of': 'Latitud', 'longitud_of': 'Longitud', 'distancia':'Distancia (KM)'})\n",
    "\n",
    "        estaciones_provincia['Distancia (KM)'] = estaciones_provincia['Distancia (KM)'].round(2)\n",
    "        estaciones_provincia[['Estacion','Latitud','Longitud','Distancia (KM)']]\n",
    "\n",
    "        #nos quedamos con la esatacion mas cercana\n",
    "\n",
    "        estacion = estaciones_provincia.iloc[0,0]\n",
    "\n",
    "\n",
    "        return estacion\n",
    "       \n",
    "       \n",
    "       # return self.estaciones\n",
    "\n",
    "    \n",
    "    #vamos a ver cuales son mis estaciones mas cercanas\n",
    "\n",
    "    def mis_estaciones_mas_cercanas(self, estaciones_provincia, estacion):\n",
    "\n",
    "\n",
    "        #print(estaciones_provincia)\n",
    "\n",
    "\n",
    "        codigo_estacion_mas_cercana = estaciones_provincia[estaciones_provincia['Estacion'] == estacion][['indicativo']]\n",
    "\n",
    "       # print(codigo_estacion_mas_cercana)\n",
    "\n",
    "        self.codigo_estacion_cercano = list(codigo_estacion_mas_cercana['indicativo'])[0]\n",
    "\n",
    "        #codigo_estacion_cercano = list(codigo_estacion_mas_cercana['indicativo'])[0]\n",
    "\n",
    "\n",
    "        return self.codigo_estacion_cercano\n",
    "\n",
    "        #return codigo_estacion_cercano\n",
    "\n",
    "\n",
    "    #obtenemos los datos de esa estacion: \n",
    "\n",
    "\n",
    "    def funciona_o_no(fecha_ini, fecha_fin, codigo, aemet):\n",
    "      \n",
    "      url = (\"https://opendata.aemet.es/opendata/api/valores/climatologicos/diarios/datos\"\n",
    "                \"/fechaini/{}T00:00:00UTC/fechafin/{}T00:00:00UTC/estacion/{}\".format(fecha_ini, fecha_fin, codigo))\n",
    "\n",
    "      API_KEY = aemet\n",
    "      querystring = {\"api_key\": API_KEY}\n",
    "          \n",
    "      r = requests.get(url, params=querystring, verify=False)\n",
    "\n",
    "      # print(r.json())\n",
    "\n",
    "\n",
    "      def parse_data(raw_data):\n",
    "          data = []\n",
    "          \n",
    "          for d in raw_data:\n",
    "              d = dict(d)  # Exto copia el parámetro\n",
    "              for param in ['prec', 'presMax', 'presMin', 'racha', 'sol', 'tmax', 'tmed', 'tmin', 'velmedia', 'altitud', 'dir']:\n",
    "                  try:\n",
    "                      d[param] = float(d[param].replace(',', '.'))\n",
    "                  except:\n",
    "                      d[param] = None\n",
    "\n",
    "              data.append(d)\n",
    "          return data\n",
    "\n",
    "      try:\n",
    "\n",
    "          #print(' El codigo en cuestion ', r.status_code)\n",
    "\n",
    "          print(r.json())\n",
    "\n",
    "          \n",
    "\n",
    "        \n",
    "\n",
    "          \n",
    "\n",
    "          if r.json()['estado'] == 200:\n",
    "\n",
    "              # print(r.json())\n",
    "\n",
    "              data_url = r.json()['datos']\n",
    "\n",
    "              return r.json()['estado']\n",
    "\n",
    "          elif r.json()['estado'] == 404:\n",
    "\n",
    "              return r.json()['estado']\n",
    "\n",
    "              #print('ERROR 404')\n",
    "\n",
    "              \n",
    "\n",
    "\n",
    "          else: \n",
    "\n",
    "              return r.json()['estado']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      except: \n",
    "\n",
    "          print('checkea las credenciales')\n",
    "\n",
    "\n",
    "    def meterelogia_estacion_mas_cercana(self, fecha_ini, fecha_fin):\n",
    "      \n",
    "        url = (\"https://opendata.aemet.es/opendata/api/valores/climatologicos/diarios/datos\"\n",
    "            \"/fechaini/{}T00:00:00UTC/fechafin/{}T00:00:00UTC/estacion/{}\".format(fecha_ini, fecha_fin, self.codigo_estacion_cercano))\n",
    "\n",
    "        API_KEY = self.aemet\n",
    "        querystring = {\"api_key\": API_KEY}\n",
    "            \n",
    "        r = requests.get(url, params=querystring, verify=False)\n",
    "\n",
    "       # print(r.json())\n",
    "\n",
    "\n",
    "        def parse_data(raw_data):\n",
    "            data = []\n",
    "            \n",
    "            for d in raw_data:\n",
    "                d = dict(d)  # Exto copia el parámetro\n",
    "                for param in ['prec', 'presMax', 'presMin', 'racha', 'sol', 'tmax', 'tmed', 'tmin', 'velmedia', 'altitud', 'dir']:\n",
    "                    try:\n",
    "                        d[param] = float(d[param].replace(',', '.'))\n",
    "                    except:\n",
    "                        d[param] = None\n",
    "\n",
    "                data.append(d)\n",
    "            return data\n",
    "\n",
    "        try:\n",
    "\n",
    "            print(' El codigo en cuestion ', r.status_code)\n",
    "\n",
    "            if r.status_code == 200:\n",
    "\n",
    "               # print(r.json())\n",
    "\n",
    "                data_url = r.json()['datos']\n",
    "\n",
    "                print('\\n La url que vamos a gestionar es: ', data_url, '\\n')\n",
    "\n",
    "                r_data = requests.get(data_url, params=querystring, verify=False)\n",
    "                #print(r_data)\n",
    "                #print('Y los datos son: ', r_data)\n",
    "                raw_data = r_data.json()\n",
    "                \n",
    "                raw_data = parse_data(raw_data)\n",
    "\n",
    "                #guardamos con los datos en el dataframe\n",
    "\n",
    "                información_base_cercana = pd.DataFrame(raw_data)\n",
    "\n",
    "                #print(información_base_cercana.head())\n",
    "\n",
    "\n",
    "                #return información_base_cercana\n",
    "\n",
    "        except: \n",
    "\n",
    "            print('La extracción de información falla, checkea las credenciales')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #---------------- EXTRAEMOS LA INFORMACIÓN DE LAS DEMÁS ESTACIONES DE LA PROVINCIA\n",
    "        # \n",
    "        def busqueda_metricas_temperatura_media(nombre_estacion, diccionario):\n",
    "\n",
    "        #0. Extraemos la información de una estación filtrando por el nombre de la estacion\n",
    "        #le añadimos el drop index, porque luego, más adelante reseeteamos el index para que el código funcione\n",
    "        #bien. Por loq ue, al genera un indice natural de python, el indice antiguo nos pasa como nueva columna y eso\n",
    "        #no nos intereesa. \n",
    "\n",
    "            #estacion_actual = estaciones_albacete[estaciones_albacete['Estacion'] == nombre_estacion].drop('index', axis = 1)\n",
    "\n",
    "            #codigo_estacion_mas_cercana = estaciones_provincia[estaciones_provincia['Estacion'] == estacion][['indicativo']]\n",
    "            #1. Nos qudamos con el código identificativo de la estacion de interes\n",
    "            \n",
    "            codigo_estacion_actual = self.codigo_estacion_cercano\n",
    "\n",
    "            # print(codigo_estacion_actual)\n",
    "\n",
    "            #2. Utilizamos el codigo de la estación para extraer la infomración metereológica\n",
    "\n",
    "            url = (\"https://opendata.aemet.es/opendata/api/valores/climatologicos/diarios/datos\"\n",
    "                \"/fechaini/{}T00:00:00UTC/fechafin/{}T00:00:00UTC/estacion/{}\".format('2021-01-01', '2022-02-10',\\\n",
    "                                                                                        codigo_estacion_actual))\n",
    "\n",
    "            API_KEY = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJraWdsZXNpYXNiYXJhaWJhckBzdHVkZW50LmVhZS5lcyIsImp0aSI6ImY4YWQ5OGRmLTkzMjQtNDEzMi05NjY3LTdjY2E2Nzc3Mzc0NiIsImlzcyI6IkFFTUVUIiwiaWF0IjoxNjQyOTYzODc0LCJ1c2VySWQiOiJmOGFkOThkZi05MzI0LTQxMzItOTY2Ny03Y2NhNjc3NzM3NDYiLCJyb2xlIjoiIn0.en7xw4HHYaZ4oW8qooX6wGG3yn1Tv3OzFfnhrZac6vo'\n",
    "\n",
    "            querystring = {\"api_key\": API_KEY}\n",
    "                \n",
    "            r = requests.get(url, params=querystring, verify=False)\n",
    "\n",
    "\n",
    "            if r.status_code == requests.codes.OK:\n",
    "                \n",
    "                #3. Nos qudamos con el apartado de 'datos' una vez transformada a json, que es una URL\n",
    "                #print(r.json())\n",
    "\n",
    "                data_url = r.json()['datos']\n",
    "\n",
    "                #4. Hacemos la petición a la API.\n",
    "\n",
    "                r_data = requests.get(data_url, params=querystring, verify=False)\n",
    "\n",
    "                #5. Hacemos la transfomración a JSON.\n",
    "\n",
    "                raw_data = r_data.json()\n",
    "\n",
    "                #6. Cambiamos los decimales de coma a punto\n",
    "\n",
    "                raw_data = parse_data(raw_data)\n",
    "                \n",
    "\n",
    "                #7. Guardamos el output en un dataframe\n",
    "\n",
    "                información_base_cercana_temp = pd.DataFrame(raw_data)\n",
    "\n",
    "                #8.Y nos quedamos con la ifnormación de la fecha y con la temperatura media de dicha estacion\n",
    "\n",
    "                información_temp_media = información_base_cercana_temp.loc[:,['fecha','tmed']]\n",
    "\n",
    "                #print('Los datos de esta estacion son: ', información_temp_media['tmed'].values.tolist()[:5])\n",
    "\n",
    "                #Finalmente, esta ifnormación la transladamos a lita para poder guardarlo junto al código de la estación de interés\n",
    "\n",
    "                diccionario[nombre_estacion] = información_temp_media['tmed'].values.tolist()\n",
    "\n",
    "            \n",
    "\n",
    "        '''\n",
    "        Dicho esto, creamos un diccionario para guardar la información de la formula que acabamos e crear, \n",
    "        y le pasamos la información de las estaciones de la provinica de interés. Pero para ello necesitamos saber cuales son \n",
    "        las estaciones de albacete\n",
    "\n",
    "        '''\n",
    "\n",
    "        url_estaciones = \"https://opendata.aemet.es/opendata/api/valores/climatologicos/inventarioestaciones/todasestaciones/\"\n",
    "        querystring = {\"api_key\":self.aemet}\n",
    "\n",
    "        headers = {\n",
    "            'cache-control': \"no-cache\"\n",
    "            }\n",
    "\n",
    "        #Como lo hemos hecho en veces anteriores, nos quedamos ocn el apartado de 'DATOS' que no deja de ser una URL. \n",
    "\n",
    "        print(requests.request(\"GET\", url_estaciones, headers=headers, params=querystring))\n",
    "\n",
    "        datos_url_plu = json.loads(requests.request(\"GET\", url_estaciones, headers=headers, params=querystring).text)['datos']\n",
    "\n",
    "        #Hacemos la request, y los resultados los guardamos en un dataframe. \n",
    "\n",
    "        todas_estaciones = pd.DataFrame(requests.get(datos_url_plu, params=querystring, verify=False).json())\n",
    "\n",
    "        #Una vez que hemos logrado las estaciones filtramos por la provincia que nos interesa.\n",
    "\n",
    "        estaciones_albacete = todas_estaciones[todas_estaciones['provincia'] == 'ALBACETE'][['indicativo', 'latitud', 'nombre', 'longitud']]\n",
    "\n",
    "        #Una vez que tenemos las estaciones de la provincia accionamos la formula creada para obtener las temepraturas medias.\n",
    "\n",
    "\n",
    "        #restablecemos el índice para que cuente desde el 0 sino no va a funcionar el script\n",
    "\n",
    "        estaciones_albacete = estaciones_albacete.rename(columns={'nombre': 'Estacion'}).reset_index()\n",
    "        #print(estaciones_albacete)\n",
    "\n",
    "\n",
    "        #print(estaciones_albacete.loc[0,'Estacion'])\n",
    "\n",
    "\n",
    "\n",
    "        #estacioness = {}\n",
    "        estaciones = {}\n",
    "\n",
    "        for estac in range(0,estaciones_albacete.shape[0]):\n",
    "\n",
    "            #por cada estacion en la tabla de estaciones de esa provincia\n",
    "            #nos quedamos con el codigo de esa provincia: \n",
    "\n",
    "            nombre_estacion = estaciones_albacete.loc[estac,'Estacion']\n",
    "            #print(nombre_estacion)\n",
    "            busqueda_metricas_temperatura_media(nombre_estacion = nombre_estacion, diccionario = estaciones)\n",
    "\n",
    "\n",
    "        #Transfomramos el output en un dataframe operativo\n",
    "\n",
    "        temperatura_media_estaciones = pd.DataFrame.from_dict(estaciones, orient='index').T\n",
    "\n",
    "        #si hay NAs los reemplazamos por 0\n",
    "\n",
    "\n",
    "        temperatura_media_estaciones = temperatura_media_estaciones.fillna(0)\n",
    "\n",
    "        #Creamos la columna de la media de las estaciones diarias\n",
    "\n",
    "        temperatura_media_estaciones['mean_tmed'] = temperatura_media_estaciones.mean(axis=1)\n",
    "\n",
    "\n",
    "        #Adjuntamos la fecha a la que se referencia cada media diaria\n",
    "\n",
    "        temperatura_media_estaciones['fecha'] = información_base_cercana['fecha']\n",
    "\n",
    "\n",
    "        #y nos quedamos solamente con los dos datos, la media diaria y la fecha\n",
    "\n",
    "        temperatura_media_estaciones = temperatura_media_estaciones[['fecha', 'mean_tmed']]\n",
    "\n",
    "        #---------------- JUNTAMOS LA INFORMACIÓN DE LAS DEMAS ESTACIONES OCN LA DE LA BASE AEREA\n",
    "\n",
    "        información_base_cercana['prov_tmed'] = temperatura_media_estaciones['mean_tmed']\n",
    "\n",
    "        #√emos el resultado del matching\n",
    "\n",
    "        #print(información_base_cercana.head())\n",
    "\n",
    "        #---------------- CREAMOS LAS NUEVAS METRICAS DE DATOS \n",
    "\n",
    "        '''\n",
    "        Si la temperatura exterior cae bajo los 7 grados, se sabe que el almendro puede empezar a caer en periodo de hibernación\n",
    "        Por lo que vamos a tener que investigar si este caso ocurre . \n",
    "        '''\n",
    "\n",
    "        import numpy as np\n",
    "\n",
    "        #primero nos interesa si ha estado dorido o no ha estado dormido\n",
    "\n",
    "        información_base_cercana['almendro_sueño'] = información_base_cercana['tmed'] < 7\n",
    "\n",
    "        #luego nos interesa saber a cuantos grados ha etado dormido si es true\n",
    "\n",
    "        información_base_cercana['dor_grados'] = 7 - información_base_cercana['tmed']\n",
    "\n",
    "        #solo queremos reperesentar los valores que ha estado realmente por debajo de 7 grados, por lo que\n",
    "        #todas aquellas veces que ha estado por encima, lo reemplazamos por 0. \n",
    "\n",
    "        información_base_cercana['dor_grados'] = np.where(información_base_cercana['dor_grados'] > 0,\\\n",
    "        información_base_cercana['dor_grados'], 0)\n",
    "\n",
    "\n",
    "        '''\n",
    "        En cuanto a la presión se refiere, también nos es de mucha interes porque es un medio que usan las \n",
    "        plantas para absorver la humedad de la tierra. \n",
    "        La presión interna tiene que ser superior a la externa. Nosotros de esta fuente solo tenemos la presión \n",
    "        externa, por lo que vamos a llamalo como tal. \n",
    "\n",
    "        '''\n",
    "\n",
    "        información_base_cercana['Presion_externa'] = (información_base_cercana['presMax'] + información_base_cercana['presMin'])/2\n",
    "\n",
    "        #--------------- CAMBIAMOS LOS NOMBRES DE LAS COLUMNAS \n",
    "\n",
    "\n",
    "        información_base_cercana = información_base_cercana[['fecha', 'nombre', \t'provincia','tmed','prec','tmin','tmax','dir','velmedia','presMax','presMin','prov_tmed','dor_grados', 'Presion_externa']]\n",
    "\n",
    "        #cambiamos los nombres de las columnas a otros más comprensibles\n",
    "\n",
    "        información_base_cercana = información_base_cercana.rename(columns={'nombre': 'Estacion', 'provincia': 'Provincia', 'tmed': 'Temperatura_media', 'prec':'Precipitacion_l_m3', 'tmin':'Temperatura_minima','tmax':'Temperatura_maxima','dir':'Direccion_viento','velmedia':'Velocidad_media','velmedia':'Velocidad_media','presMax':'Presion_maxima', 'presMin':'Presion_minima', 'prov_tmed':'Prom_temperatura_media_prov', 'dor_grados':'Grados_debajo_siete'})\n",
    "\n",
    "\n",
    "        return información_base_cercana\n",
    "\n",
    "\n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8oZSW_y5zd3"
   },
   "source": [
    "# Prueba de funcionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M7ysoVDN51ay"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Busqueda por coordenadas\n",
      "la provincia es:  Valencian Community\n",
      "Tenemos info geolocalizada :) \n",
      " 40.5206 ,  0.351246\n",
      "Provincia optenida :) \n",
      " VALENCIAN COMMUNITY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'opendata.aemet.es'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Estacion  latitud_of  longitud_of indicativo\n",
      "0                OLIVA   38.928889    -0.095833      8058X\n",
      "1    POLINYÀ DE XÚQUER   39.184722    -0.371944      8325X\n",
      "2                UTIEL   39.575556    -1.244722      8309X\n",
      "3  VALENCIA AEROPUERTO   39.485000    -0.474722      8414A\n",
      "4    VALÈNCIA, VIVEROS   39.480556    -0.366389      8416Y\n",
      "5             VALÈNCIA   39.480556    -0.366389       8416\n",
      "6               XÀTIVA   39.001667    -0.523611      8293X\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'opendata.aemet.es'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El codigo en cuestion  200\n",
      "\n",
      " La url que vamos a gestionar es:  https://opendata.aemet.es/opendata/sh/d3225224 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'opendata.aemet.es'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'opendata.aemet.es'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'opendata.aemet.es'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'opendata.aemet.es'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'opendata.aemet.es'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'opendata.aemet.es'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'opendata.aemet.es'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'opendata.aemet.es'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'opendata.aemet.es'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/Users/kaietiglesiasbaraibar/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'opendata.aemet.es'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          fecha           Estacion Provincia  Temperatura_media  \\\n",
      "0    2021-01-01  VALÈNCIA, VIVEROS  VALENCIA               10.6   \n",
      "1    2021-01-02  VALÈNCIA, VIVEROS  VALENCIA                8.0   \n",
      "2    2021-01-03  VALÈNCIA, VIVEROS  VALENCIA                9.5   \n",
      "3    2021-01-04  VALÈNCIA, VIVEROS  VALENCIA                9.4   \n",
      "4    2021-01-05  VALÈNCIA, VIVEROS  VALENCIA                8.0   \n",
      "..          ...                ...       ...                ...   \n",
      "420  2022-02-25  VALÈNCIA, VIVEROS  VALENCIA               12.6   \n",
      "421  2022-02-26  VALÈNCIA, VIVEROS  VALENCIA               11.5   \n",
      "422  2022-02-27  VALÈNCIA, VIVEROS  VALENCIA               12.4   \n",
      "423  2022-02-28  VALÈNCIA, VIVEROS  VALENCIA               12.9   \n",
      "424  2022-03-01  VALÈNCIA, VIVEROS  VALENCIA               13.3   \n",
      "\n",
      "     Precipitacion_l_m3  Temperatura_minima  Temperatura_maxima  \\\n",
      "0                   1.5                 6.9                14.4   \n",
      "1                   0.0                 3.8                12.1   \n",
      "2                   0.0                 3.5                15.5   \n",
      "3                   0.0                 5.6                13.1   \n",
      "4                   0.0                 2.4                13.5   \n",
      "..                  ...                 ...                 ...   \n",
      "420                 1.9                11.0                14.1   \n",
      "421                 0.1                10.0                13.0   \n",
      "422                 0.0                 9.9                14.9   \n",
      "423                 0.0                 8.9                16.9   \n",
      "424                 0.0                 6.8                19.8   \n",
      "\n",
      "     Direccion_viento  Velocidad_media  Presion_maxima  Presion_minima  \\\n",
      "0                26.0              1.9             999             999   \n",
      "1                36.0              2.2             999             999   \n",
      "2                24.0              2.2             999             999   \n",
      "3                99.0              3.3             999             999   \n",
      "4                26.0              1.9             999             999   \n",
      "..                ...              ...             ...             ...   \n",
      "420              36.0              0.8             999             999   \n",
      "421               9.0              2.2             999             999   \n",
      "422              21.0              1.1             999             999   \n",
      "423               8.0              1.7             999             999   \n",
      "424              12.0              1.7             999             999   \n",
      "\n",
      "     Prom_temperatura_media_prov  Grados_debajo_siete  Presion_externa  \n",
      "0                           10.6                  0.0              999  \n",
      "1                            8.0                  0.0              999  \n",
      "2                            9.5                  0.0              999  \n",
      "3                            9.4                  0.0              999  \n",
      "4                            8.0                  0.0              999  \n",
      "..                           ...                  ...              ...  \n",
      "420                        999.0                  0.0              999  \n",
      "421                        999.0                  0.0              999  \n",
      "422                        999.0                  0.0              999  \n",
      "423                        999.0                  0.0              999  \n",
      "424                        999.0                  0.0              999  \n",
      "\n",
      "[425 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. EJEMPLO USANDO COORDENADAS\n",
    "\n",
    "#1. Cargamos la clase\n",
    "\n",
    "api_key_bluetab = 'AIzaSyD7zvwwj8-4JS2XZq0n8bLb9t2cSqStx84'\n",
    "\n",
    "api_aemet = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJraWdsZXNpYXNiYXJhaWJhckBzdHVkZW50LmVhZS5lcyIsImp0aSI6ImY4YWQ5OGRmLTkzMjQtNDEzMi05NjY3LTdjY2E2Nzc3Mzc0NiIsImlzcyI6IkFFTUVUIiwiaWF0IjoxNjQyOTYzODc0LCJ1c2VySWQiOiJmOGFkOThkZi05MzI0LTQxMzItOTY2Ny03Y2NhNjc3NzM3NDYiLCJyb2xlIjoiIn0.en7xw4HHYaZ4oW8qooX6wGG3yn1Tv3OzFfnhrZac6vo'\n",
    "\n",
    "\n",
    "#api_key_kaiet = 'AIzaSyB8b6vSNPb7MzEBXXTNRzdkWqLGIKQotmU'\n",
    "mi_metereologia_clase = mi_metereologia( google_maps_key = api_key_bluetab,\\\n",
    "    coodenadas = (40.5206, 0.351246),\\\n",
    "    api_aemet =  api_aemet)\n",
    "\n",
    "\n",
    "#Sacamos que provincia me corresponde con la ubicacion que he pasado\n",
    "\n",
    "provincia =  mi_metereologia_clase.address()\n",
    "\n",
    "\n",
    "\n",
    "#Sacamos las esatciones de dicha provincia\n",
    "\n",
    "estaciones_provincia = mi_metereologia_clase.estaciones()\n",
    "\n",
    "print(estaciones_provincia)\n",
    "\n",
    "#Extraigo mi latitud y longitud\n",
    "mi_ubicacion = mi_metereologia_clase.mi_latlon()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Sacamos la distancias que tengo a las estaciones de mi alrededor\n",
    "\n",
    "mis_estaciones_distancias_brutas = mi_metereologia_clase.distancias()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#estaciones_provincia['distancia'] = mis_estaciones_distancias_brutas\n",
    "\n",
    "\n",
    "#Falta sacar la estacion más cercana\n",
    "\n",
    "\n",
    "estaciones_ordenadas = mi_metereologia_clase.ordenar_distancias(mis_estaciones_distancias_brutas)\n",
    "\n",
    "estacion_mas_cercana_codigo = mi_metereologia_clase.mis_estaciones_mas_cercanas(estaciones_provincia, estaciones_ordenadas)\n",
    "\n",
    "\n",
    "#print(estacion_mas_cercana_codigo)\n",
    "\n",
    "#hacer la llamada a la api de aemet\n",
    "\n",
    "\n",
    "#mis_datos = mi_metereologia_clase.meterelogia_estacion_mas_cercana()\n",
    "\n",
    "\n",
    "#print(mis_datos.head())\n",
    "\n",
    "df = mi_metereologia_clase.meterelogia_estacion_mas_cercana(fecha_ini =  '2021-01-01', fecha_fin = '2022-03-01')\n",
    "\n",
    "df = df.fillna(999)\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cY52_9M-iDT-"
   },
   "source": [
    "## Subimos los datos a la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sKTGv-e54S1",
    "outputId": "009f9a4e-9ea5-4dad-f78b-f4cee9a12c3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pymysql\n",
      "Successfully installed pymysql-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_2I1J8n3iUUd"
   },
   "outputs": [],
   "source": [
    "#El objetivo de esta función es la construcción de una función que sirva para insertar \n",
    "#lineas en una tabla de sql.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "#import cryptography\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "------------------- AWS OLD CONNECTION --------------\n",
    "host = 'database-1.cq2dp4jmizro.eu-west-1.rds.amazonaws.com'\n",
    "user = 'admin'\n",
    "password = '12345678'\n",
    "database = 'GET_DATABASE'\n",
    "\n",
    "'''\n",
    "#----------------------- GCP connection-----------------\n",
    "\n",
    "host = '35.241.159.127' #este el el host nuevo\n",
    "user = 'admin'\n",
    "password = '12345678'\n",
    "database = 'GET_DATABASE'\n",
    "\n",
    "def insert_into(data, arrival_df):\n",
    "\n",
    "    #establecemos la conexión a la base de datos\n",
    "    connection = pymysql.connect(host=host,\n",
    "                             user=user,\n",
    "                             password=password,\n",
    "                             db=database)\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "\n",
    "    #especificamos cual es el nombre de la tabla destino\n",
    "\n",
    "    nombre_tabla = arrival_df\n",
    "\n",
    "    \n",
    "    # creating column list for insertion\n",
    "    cols = \"`,`\".join([str(i) for i in data.columns.tolist()])\n",
    "    cols = cols.strip()\n",
    "    # Insert DataFrame recrds one by one.\n",
    "    for i,row in data.iterrows():\n",
    "        sql = \"INSERT INTO `{}` (`\".format(nombre_tabla) +cols + \"`) VALUES (\" + \"%s,\"*(len(row)-1) + \"%s)\"\n",
    "\n",
    "            \n",
    "        cursor.execute(sql, tuple(row))\n",
    "\n",
    "            # the connection is not autocommitted by default, so we must commit to save our changes\n",
    "        connection.commit()\n",
    "\n",
    "\n",
    "def run_query(q):\n",
    "  with pymysql.connect(host=host,\n",
    "                             user=user,\n",
    "                             password=password,\n",
    "                             db=database) as conn:\n",
    "                             return pd.read_sql(q, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ih5xrkAgiXc1",
    "outputId": "e638b69c-8d0f-42b6-fbaa-d5b9726ce2c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Busqueda por coordenadas\n",
      "la provincia es:  Valencian Community\n",
      "Tenemos info geolocalizada :) \n",
      " 40.5206 ,  0.351246\n",
      "Provincia optenida :) \n",
      " VALENCIAN COMMUNITY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Estacion  latitud_of  longitud_of indicativo\n",
      "0                OLIVA   38.928889    -0.095833      8058X\n",
      "1    POLINYÀ DE XÚQUER   39.184722    -0.371944      8325X\n",
      "2                UTIEL   39.575556    -1.244722      8309X\n",
      "3  VALENCIA AEROPUERTO   39.485000    -0.474722      8414A\n",
      "4    VALÈNCIA, VIVEROS   39.480556    -0.366389      8416Y\n",
      "5             VALÈNCIA   39.480556    -0.366389       8416\n",
      "6               XÀTIVA   39.001667    -0.523611      8293X\n",
      "\n",
      " ######################### \n",
      "\n",
      "Estamos en  2021  en  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'descripcion': 'exito', 'estado': 200, 'datos': 'https://opendata.aemet.es/opendata/sh/7dc08981', 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "{'2021-1': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El codigo en cuestion  200\n",
      "\n",
      " La url que vamos a gestionar es:  https://opendata.aemet.es/opendata/sh/7dc08981 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######################### \n",
      "\n",
      "Estamos en  2021  en  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'descripcion': 'exito', 'estado': 200, 'datos': 'https://opendata.aemet.es/opendata/sh/d4bfb03f', 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "{'2021-1': 200, '2021-2': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El codigo en cuestion  200\n",
      "\n",
      " La url que vamos a gestionar es:  https://opendata.aemet.es/opendata/sh/d4bfb03f \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######################### \n",
      "\n",
      "Estamos en  2021  en  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'descripcion': 'exito', 'estado': 200, 'datos': 'https://opendata.aemet.es/opendata/sh/4f44e15f', 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "{'2021-1': 200, '2021-2': 200, '2021-3': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El codigo en cuestion  200\n",
      "\n",
      " La url que vamos a gestionar es:  https://opendata.aemet.es/opendata/sh/4f44e15f \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######################### \n",
      "\n",
      "Estamos en  2021  en  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'descripcion': 'exito', 'estado': 200, 'datos': 'https://opendata.aemet.es/opendata/sh/33f430fb', 'metadatos': 'https://opendata.aemet.es/opendata/sh/b3aa9d28'}\n",
      "{'2021-1': 200, '2021-2': 200, '2021-3': 200, '2021-4': 200}\n",
      " El codigo en cuestion  200\n",
      "\n",
      " La url que vamos a gestionar es:  https://opendata.aemet.es/opendata/sh/33f430fb \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-9b07be9b9e77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmi_metereologia_clase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeterelogia_estacion_mas_cercana\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfecha_ini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}-{}-01'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mano\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfecha_fin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}-{}-31'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mano\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m           \u001b[0;31m#Se reemplazan los nas por 999\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-5ff0579f7fe0>\u001b[0m in \u001b[0;36mmeterelogia_estacion_mas_cercana\u001b[0;34m(self, fecha_ini, fecha_fin)\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;31m#Hacemos la request, y los resultados los guardamos en un dataframe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mtodas_estaciones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos_url_plu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquerystring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m#Una vez que hemos logrado las estaciones filtramos por la provincia que nos interesa.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import requests\n",
    "\n",
    "host = '35.241.159.127' #este el el host nuevo\n",
    "user = 'admin'\n",
    "password = '12345678'\n",
    "database = 'GET_DATABASE'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def conectame(host, user, password, database):\n",
    "\n",
    "    #conn = pymysql.connect(host=host, user=user, password=password, port=3306, db='GET_DATABASE',charset='utf8')\n",
    "\n",
    "    connection = pymysql.connect(host=host,\n",
    "                                user=user,\n",
    "                                password=password,\n",
    "                                db=database)\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    return cursor\n",
    "cursor = conectame(host, user, password, database)\n",
    "'''\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "try:\n",
    "    conn = pymysql.connect(host=host, user=user, passwd=password, db=database, connect_timeout=5)\n",
    "except pymysql.MySQLError as e:\n",
    "    logger.error(\"ERROR: Unexpected error: Could not connect to MySQL instance.\")\n",
    "    logger.error(e)\n",
    "    sys.exit()\n",
    "\n",
    "logger.info(\"SUCCESS: Connection to RDS MySQL instance succeeded\")\n",
    "\n",
    "#------------------ creamos la tabla ---------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def checkTableExists(conn, tablename):\n",
    "    dbcur = conn.cursor()\n",
    "    dbcur.execute(\"\"\"\n",
    "        SELECT COUNT(*)\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_name = '{0}'\n",
    "        \"\"\".format(tablename.replace('\\'', '\\'\\'')))\n",
    "    if dbcur.fetchone()[0] == 1:\n",
    "        dbcur.close()\n",
    "        return True\n",
    "\n",
    "    dbcur.close()\n",
    "    return False\n",
    "\n",
    "#------------ ESPECIFICAMOS CUAL VA A SER LA TABLA DE INTERÉS------\n",
    "\n",
    "tabla_de_interes = 'DATOS_METEREOLOGIA_HISTORICO_TBA'\n",
    "\n",
    "#------------- LANZAMOS PARTE DEL CODIGO DE LA CLASE PARA OBTENRER INPUTS -----\n",
    "\n",
    "\n",
    "#1. Cargamos la clase\n",
    "\n",
    "api_key_bluetab = 'AIzaSyD7zvwwj8-4JS2XZq0n8bLb9t2cSqStx84'\n",
    "\n",
    "api_aemet = 'eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJraWdsZXNpYXNiYXJhaWJhckBzdHVkZW50LmVhZS5lcyIsImp0aSI6ImY4YWQ5OGRmLTkzMjQtNDEzMi05NjY3LTdjY2E2Nzc3Mzc0NiIsImlzcyI6IkFFTUVUIiwiaWF0IjoxNjQyOTYzODc0LCJ1c2VySWQiOiJmOGFkOThkZi05MzI0LTQxMzItOTY2Ny03Y2NhNjc3NzM3NDYiLCJyb2xlIjoiIn0.en7xw4HHYaZ4oW8qooX6wGG3yn1Tv3OzFfnhrZac6vo'\n",
    "\n",
    "\n",
    "#api_key_kaiet = 'AIzaSyB8b6vSNPb7MzEBXXTNRzdkWqLGIKQotmU'\n",
    "mi_metereologia_clase = mi_metereologia( google_maps_key = api_key_bluetab,\\\n",
    "    coodenadas = (40.5206, 0.351246),\\\n",
    "    api_aemet =  api_aemet)\n",
    "\n",
    "\n",
    "#Sacamos que provincia me corresponde con la ubicacion que he pasado\n",
    "\n",
    "provincia =  mi_metereologia_clase.address()\n",
    "\n",
    "\n",
    "\n",
    "#Sacamos las esatciones de dicha provincia\n",
    "\n",
    "estaciones_provincia = mi_metereologia_clase.estaciones()\n",
    "\n",
    "print(estaciones_provincia)\n",
    "\n",
    "#Extraigo mi latitud y longitud\n",
    "mi_ubicacion = mi_metereologia_clase.mi_latlon()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Sacamos la distancias que tengo a las estaciones de mi alrededor\n",
    "\n",
    "mis_estaciones_distancias_brutas = mi_metereologia_clase.distancias()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#estaciones_provincia['distancia'] = mis_estaciones_distancias_brutas\n",
    "\n",
    "\n",
    "#Falta sacar la estacion más cercana\n",
    "\n",
    "\n",
    "estaciones_ordenadas = mi_metereologia_clase.ordenar_distancias(mis_estaciones_distancias_brutas)\n",
    "\n",
    "estacion_mas_cercana_codigo = mi_metereologia_clase.mis_estaciones_mas_cercanas(estaciones_provincia, estaciones_ordenadas)\n",
    "\n",
    "\n",
    "# Y finalmente usamos el ultimo metodo ode la clase para obtener daos\n",
    "# de unas fechas exactas y lainsertamos en la base de datos\n",
    "\n",
    "\n",
    "resultado = {}\n",
    "\n",
    "if checkTableExists(conn, tabla_de_interes):\n",
    "\n",
    "  for ano in range(2021, 2022):\n",
    "\n",
    "    for mes in range(1,12):\n",
    "      \n",
    "      print('\\n ######################### \\n')\n",
    "\n",
    "      print('Estamos en ', ano, ' en ', mes)\n",
    "\n",
    "      \n",
    "\n",
    "      resultadofin  = mi_metereologia.funciona_o_no(fecha_ini = '{}-{}-01'.format(ano, mes),\\\n",
    "                                                    fecha_fin = '{}-{}-31'.format(ano, mes),\\\n",
    "                                                    codigo = estacion_mas_cercana_codigo, \\\n",
    "                                                    aemet = api_aemet)\n",
    "      \n",
    "\n",
    "      tiempo = '{}-{}'.format(ano, mes)\n",
    "\n",
    "      if resultadofin != 200:\n",
    "        \n",
    "        continue\n",
    "\n",
    "      else:\n",
    "\n",
    "        resultado[tiempo] = resultadofin\n",
    "\n",
    "        print(resultado)\n",
    "\n",
    "\n",
    "        df = mi_metereologia_clase.meterelogia_estacion_mas_cercana(fecha_ini = '{}-{}-01'.format(ano, mes), fecha_fin = '{}-{}-31'.format(ano, mes))\n",
    "          \n",
    "          #Se reemplazan los nas por 999\n",
    "\n",
    "        df = df.fillna(999)\n",
    "\n",
    "          #print(df.head())\n",
    "\n",
    "\n",
    "          #-------- SUBIMOS LOS DATOS --------#\n",
    "\n",
    "        insert_into(df, tabla_de_interes)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "  \n",
    "  \n",
    "else:\n",
    "    \n",
    "  q = '''CREATE TABLE {}(\n",
    "\n",
    "    fecha   DATE NOT NULL, \n",
    "    Estacion VARCHAR(255) NOT NULL, \n",
    "    Provincia VARCHAR(255), \n",
    "    Temperatura_media INT,\n",
    "    Precipitacion_l_m3 INT, \n",
    "        Temperatura_minima float, \n",
    "        Temperatura_maxima float,\n",
    "        Direccion_viento VARCHAR(255), \n",
    "        Velocidad_media float, \n",
    "        Presion_maxima float,\n",
    "          Presion_minima float, \n",
    "          Prom_temperatura_media_prov float, \n",
    "          Grados_debajo_siete float,\n",
    "          Presion_externa float\n",
    "          \n",
    "          );'''.format(tabla_de_interes)\n",
    "\n",
    "\n",
    "  print(run_query(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlsBWwj1pPMD",
    "outputId": "9e3bb95b-f52b-4707-d00b-d5224a6665d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2021-1': 200, '2021-2': 200, '2021-3': 200, '2021-4': 200}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "RIn6a7EOka3S",
    "outputId": "961a349e-edd6-42db-a57e-d9a895e2cfbc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c359ab4b-c6ed-4630-8a53-b11cb0512a77\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-06-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-06-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>2021-11-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>2021-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>2021-11-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>2021-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>2021-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5556 rows × 1 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c359ab4b-c6ed-4630-8a53-b11cb0512a77')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c359ab4b-c6ed-4630-8a53-b11cb0512a77 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c359ab4b-c6ed-4630-8a53-b11cb0512a77');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           fecha\n",
       "0     2005-06-01\n",
       "1     2005-06-02\n",
       "2     2005-06-03\n",
       "3     2005-06-04\n",
       "4     2005-06-05\n",
       "...          ...\n",
       "5551  2021-11-27\n",
       "5552  2021-11-28\n",
       "5553  2021-11-29\n",
       "5554  2021-11-30\n",
       "5555  2021-12-01\n",
       "\n",
       "[5556 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "q = '''\n",
    "\n",
    "select fecha from DATOS_METEREOLOGIA_HISTORICO_TBA;\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "run_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjKmpWhekiYj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "METEREOLOGIA_HISTORICO_TBA.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
